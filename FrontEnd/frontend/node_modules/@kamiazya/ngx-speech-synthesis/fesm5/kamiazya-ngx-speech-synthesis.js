import { InjectionToken, Injectable, NgModule, Optional, Inject, defineInjectable, inject } from '@angular/core';

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
/** @type {?} */
var Lang = new InjectionToken('speech-synthesis.lang');
/** @type {?} */
var Voice = new InjectionToken('speech-synthesis.voice');
/** @type {?} */
var Volume = new InjectionToken('speech-synthesis.volume');
/** @type {?} */
var Rate = new InjectionToken('speech-synthesis.rate');
/** @type {?} */
var Pitch = new InjectionToken('speech-synthesis.pitch');
/** @type {?} */
var OnStartHandler = new InjectionToken('speech-synthesis.onstart');
/** @type {?} */
var OnEndHandler = new InjectionToken('speech-synthesis.onend');
/** @type {?} */
var OnErrorHandler = new InjectionToken('speech-synthesis.onerror');
/** @type {?} */
var OnPauseHandler = new InjectionToken('speech-synthesis.onpause');
/** @type {?} */
var OnResumeHandler = new InjectionToken('speech-synthesis.onresume');
/** @type {?} */
var OnMarkHandler = new InjectionToken('speech-synthesis.onmark');
/** @type {?} */
var OnBoundaryHandler = new InjectionToken('speech-synthesis.onboundary');
/** @type {?} */
var Params = new InjectionToken('speech-synthesis.params');
/** @type {?} */
var Config = new InjectionToken('speech-synthesis.config');

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
var SpeechSynthesisService = /** @class */ (function () {
    function SpeechSynthesisService() {
        this.internal = window.speechSynthesis;
    }
    Object.defineProperty(SpeechSynthesisService.prototype, "pending", {
        /**
         * This attribute is true if the queue for
         * the global SpeechSynthesis instance contains any utterances
         * which have not started speaking.
         */
        get: /**
         * This attribute is true if the queue for
         * the global SpeechSynthesis instance contains any utterances
         * which have not started speaking.
         * @return {?}
         */
        function () {
            return this.internal.pending;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(SpeechSynthesisService.prototype, "speaking", {
        /**
         * This attribute is true if an utterance is being spoken.
         * Specifically if an utterance has begun being spoken
         * and has not completed being spoken.
         * This is independent of whether the global SpeechSynthesis instance is
         * in the paused state.
         */
        get: /**
         * This attribute is true if an utterance is being spoken.
         * Specifically if an utterance has begun being spoken
         * and has not completed being spoken.
         * This is independent of whether the global SpeechSynthesis instance is
         * in the paused state.
         * @return {?}
         */
        function () {
            return this.internal.speaking;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(SpeechSynthesisService.prototype, "paused", {
        /**
         * This attribute is true when the global SpeechSynthesis instance is
         * in the paused state.
         * This state is independent of whether anything is in the queue.
         * The default state of a the global SpeechSynthesis instance
         * for a new window is the non-paused state.
         */
        get: /**
         * This attribute is true when the global SpeechSynthesis instance is
         * in the paused state.
         * This state is independent of whether anything is in the queue.
         * The default state of a the global SpeechSynthesis instance
         * for a new window is the non-paused state.
         * @return {?}
         */
        function () {
            return this.internal.paused;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(SpeechSynthesisService.prototype, "onvoiceschanged", {
        /**
         * Fired when the contents of the SpeechSynthesisVoiceList,
         * that the getVoices method will return, have changed.
         * Examples include: server-side synthesis where the list is determined asynchronously,
         * or when client-side voices are installed/uninstalled.
         */
        set: /**
         * Fired when the contents of the SpeechSynthesisVoiceList,
         * that the getVoices method will return, have changed.
         * Examples include: server-side synthesis where the list is determined asynchronously,
         * or when client-side voices are installed/uninstalled.
         * @param {?} handler
         * @return {?}
         */
        function (handler) {
            this.internal.onvoiceschanged = handler;
        },
        enumerable: true,
        configurable: true
    });
    /**
     * This method appends the SpeechSynthesisUtterance object utterance
     * to the end of the queue for the global SpeechSynthesis instance.
     * It does not change the paused state of the SpeechSynthesis instance.
     * If the SpeechSynthesis instance is paused, it remains paused.
     * If it is not paused and no other utterances are in the queue,
     * then this utterance is spoken immediately, else this utterance is queued
     * to begin speaking after the other utterances in the queue have been spoken.
     * If changes are made to the SpeechSynthesisUtterance object after calling
     * this method and prior to the corresponding end or error event,
     * it is not defined whether those changes will affect what is spoken,
     * and those changes may cause an error to be returned.
     * The SpeechSynthesis object takes exclusive ownership of the SpeechSynthesisUtterance object.
     * Passing it as a speak() argument to another SpeechSynthesis object should throw an exception.
     * (For example, two frames may have the same origin and each will contain a SpeechSynthesis object.)
     */
    /**
     * This method appends the SpeechSynthesisUtterance object utterance
     * to the end of the queue for the global SpeechSynthesis instance.
     * It does not change the paused state of the SpeechSynthesis instance.
     * If the SpeechSynthesis instance is paused, it remains paused.
     * If it is not paused and no other utterances are in the queue,
     * then this utterance is spoken immediately, else this utterance is queued
     * to begin speaking after the other utterances in the queue have been spoken.
     * If changes are made to the SpeechSynthesisUtterance object after calling
     * this method and prior to the corresponding end or error event,
     * it is not defined whether those changes will affect what is spoken,
     * and those changes may cause an error to be returned.
     * The SpeechSynthesis object takes exclusive ownership of the SpeechSynthesisUtterance object.
     * Passing it as a speak() argument to another SpeechSynthesis object should throw an exception.
     * (For example, two frames may have the same origin and each will contain a SpeechSynthesis object.)
     * @param {?} utterance
     * @return {?}
     */
    SpeechSynthesisService.prototype.speak = /**
     * This method appends the SpeechSynthesisUtterance object utterance
     * to the end of the queue for the global SpeechSynthesis instance.
     * It does not change the paused state of the SpeechSynthesis instance.
     * If the SpeechSynthesis instance is paused, it remains paused.
     * If it is not paused and no other utterances are in the queue,
     * then this utterance is spoken immediately, else this utterance is queued
     * to begin speaking after the other utterances in the queue have been spoken.
     * If changes are made to the SpeechSynthesisUtterance object after calling
     * this method and prior to the corresponding end or error event,
     * it is not defined whether those changes will affect what is spoken,
     * and those changes may cause an error to be returned.
     * The SpeechSynthesis object takes exclusive ownership of the SpeechSynthesisUtterance object.
     * Passing it as a speak() argument to another SpeechSynthesis object should throw an exception.
     * (For example, two frames may have the same origin and each will contain a SpeechSynthesis object.)
     * @param {?} utterance
     * @return {?}
     */
    function (utterance) {
        this.internal.speak(utterance);
    };
    /**
     * This method removes all utterances from the queue.
     * If an utterance is being spoken, speaking ceases immediately.
     * This method does not change the paused state of the global SpeechSynthesis instance.
     */
    /**
     * This method removes all utterances from the queue.
     * If an utterance is being spoken, speaking ceases immediately.
     * This method does not change the paused state of the global SpeechSynthesis instance.
     * @return {?}
     */
    SpeechSynthesisService.prototype.cancel = /**
     * This method removes all utterances from the queue.
     * If an utterance is being spoken, speaking ceases immediately.
     * This method does not change the paused state of the global SpeechSynthesis instance.
     * @return {?}
     */
    function () {
        this.internal.cancel();
    };
    /**
     * This method puts the global SpeechSynthesis instance into the paused state.
     * If an utterance was being spoken, it pauses mid-utterance.
     * (If called when the SpeechSynthesis instance was already in the paused state, it does nothing.)
     */
    /**
     * This method puts the global SpeechSynthesis instance into the paused state.
     * If an utterance was being spoken, it pauses mid-utterance.
     * (If called when the SpeechSynthesis instance was already in the paused state, it does nothing.)
     * @return {?}
     */
    SpeechSynthesisService.prototype.pause = /**
     * This method puts the global SpeechSynthesis instance into the paused state.
     * If an utterance was being spoken, it pauses mid-utterance.
     * (If called when the SpeechSynthesis instance was already in the paused state, it does nothing.)
     * @return {?}
     */
    function () {
        this.internal.pause();
    };
    /**
     * This method puts the global SpeechSynthesis instance into the non-paused state.
     * If an utterance was speaking, it continues speaking the utterance
     * at the point at which it was paused, else it begins speaking
     * the next utterance in the queue (if any).
     * (If called when the SpeechSynthesis instance was already in the non-paused state, it does nothing.)
     */
    /**
     * This method puts the global SpeechSynthesis instance into the non-paused state.
     * If an utterance was speaking, it continues speaking the utterance
     * at the point at which it was paused, else it begins speaking
     * the next utterance in the queue (if any).
     * (If called when the SpeechSynthesis instance was already in the non-paused state, it does nothing.)
     * @return {?}
     */
    SpeechSynthesisService.prototype.resume = /**
     * This method puts the global SpeechSynthesis instance into the non-paused state.
     * If an utterance was speaking, it continues speaking the utterance
     * at the point at which it was paused, else it begins speaking
     * the next utterance in the queue (if any).
     * (If called when the SpeechSynthesis instance was already in the non-paused state, it does nothing.)
     * @return {?}
     */
    function () {
        this.internal.resume();
    };
    /**
     * This method returns the available voices.
     * It is user agent dependent which voices are available.
     * If there are no voices available, or if the the list of available voices
     * is not yet known (for example: server-side synthesis where the list is determined asynchronously),
     * then this method must return a SpeechSynthesisVoiceList of length zero.
     */
    /**
     * This method returns the available voices.
     * It is user agent dependent which voices are available.
     * If there are no voices available, or if the the list of available voices
     * is not yet known (for example: server-side synthesis where the list is determined asynchronously),
     * then this method must return a SpeechSynthesisVoiceList of length zero.
     * @return {?}
     */
    SpeechSynthesisService.prototype.getVoices = /**
     * This method returns the available voices.
     * It is user agent dependent which voices are available.
     * If there are no voices available, or if the the list of available voices
     * is not yet known (for example: server-side synthesis where the list is determined asynchronously),
     * then this method must return a SpeechSynthesisVoiceList of length zero.
     * @return {?}
     */
    function () {
        return this.internal.getVoices();
    };
    SpeechSynthesisService.decorators = [
        { type: Injectable, args: [{
                    providedIn: 'root'
                },] }
    ];
    /** @nocollapse */
    SpeechSynthesisService.ctorParameters = function () { return []; };
    /** @nocollapse */ SpeechSynthesisService.ngInjectableDef = defineInjectable({ factory: function SpeechSynthesisService_Factory() { return new SpeechSynthesisService(); }, token: SpeechSynthesisService, providedIn: "root" });
    return SpeechSynthesisService;
}());

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
/**
 * \@dynamic
 */
var SpeechSynthesisUtteranceFactoryService = /** @class */ (function () {
    function SpeechSynthesisUtteranceFactoryService(config, 
    /**
     * This attribute specifies the language of the speech synthesis for the utterance,
     * using a valid BCP 47 language tag.
     * [BCP47] If unset it remains unset for getting in script,
     * but will default to use the language of the html document root element and associated hierarchy.
     * This default value is computed and used when the input request opens a connection
     * to the recognition service.
     */
    lang, 
    /**
     * This attribute specifies the speech synthesis voice that the web application wishes to use.
     * When a SpeechSynthesisUtterance object is created this attribute must be initialized to null.
     * If, at the time of the speak() method call,
     * this attribute has been set to one of the SpeechSynthesisVoice objects returned by getVoices(),
     * then the user agent must use that voice. If this attribute is unset or null at the time of the speak()
     * method call, then the user agent must use a user agent default voice.
     * The user agent default voice should support the current language (see lang) and
     * can be a local or remote speech service and can incorporate end user choices via interfaces
     * provided by the user agent such as browser configuration parameters.
     */
    voice, 
    /**
     * This attribute specifies the speaking volume for the utterance.
     * It ranges between 0 and 1 inclusive, with 0 being the lowest volume and 1 the highest volume,
     * with a default of 1. If SSML is used, this value will be overridden by prosody tags in the markup.
     */
    volume, 
    /**
     * This attribute specifies the speaking rate for the utterance.
     * It is relative to the default rate for this voice.
     * 1 is the default rate supported by the speech synthesis engine or specific voice
     * (which should correspond to a normal speaking rate).
     * 2 is twice as fast, and 0.5 is half as fast. Values below 0.1 or above 10 are strictly disallowed,
     * but speech synthesis engines or specific voices may constrain the minimum and maximum rates further,
     * for example, a particular voice may not actually speak faster than 3 times normal
     * even if you specify a value larger than 3.
     * If SSML is used, this value will be overridden by prosody tags in the markup.
     */
    rate, 
    /**
     * This attribute specifies the speaking pitch for the utterance.
     * It ranges between 0 and 2 inclusive, with 0 being the lowest pitch and 2 the highest pitch.
     * 1 corresponds to the default pitch of the speech synthesis engine or specific voice.
     * Speech synthesis engines or voices may constrain the minimum and maximum rates further.
     * If SSML is used, this value will be overridden by prosody tags in the markup.
     */
    pitch, 
    /**
     * Fired when this utterance has begun to be spoken.
     */
    onstart, 
    /**
     * Fired when this utterance has completed being spoken. If this event fires,
     * the error event must not be fired for this utterance.
     */
    onend, 
    /**
     * Fired if there was an error that prevented successful speaking of this utterance.
     * If this event fires, the end event must not be fired for this utterance.
     */
    onerror, 
    /**
     * Fired when and if this utterance is paused mid-utterance.
     */
    onpause, 
    /**
     * Fired when and if this utterance is resumed after being paused mid-utterance.
     * Adding the utterance to the queue while the global SpeechSynthesis instance is in the paused state,
     * and then calling the resume method does not cause the resume event to be fired,
     * in this case the utterance’s start event will be called when the utterance starts.
     */
    onresume, 
    /**
     * Fired when the spoken utterance reaches a named "mark" tag in SSML.
     * [SSML] The user agent must fire this event if the speech synthesis engine provides the event.
     */
    onmark, 
    /**
     * Fired when the spoken utterance reaches a word or sentence boundary.
     * The user agent must fire this event if the speech synthesis engine provides the event.
     */
    onboundary) {
        var _this = this;
        this.internal = window.speechSynthesis;
        this._config = config;
        this._lang = lang;
        if (typeof voice === 'string') {
            this.internal
                .addEventListener('voiceschanged', function () {
                _this._voice = _this.internal
                    .getVoices().find(function (v) { return v.name === voice; });
            });
        }
        else {
            this._voice = voice;
        }
        this._volume = volume;
        this._rate = rate;
        this._pitch = pitch;
        this._onstart = onstart;
        this._onend = onend;
        this._onerror = onerror;
        this._onpause = onpause;
        this._onresume = onresume;
        this._onmark = onmark;
        this._onboundary = onboundary;
    }
    Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "lang", {
        /**
         * This attribute specifies the language of the speech synthesis for the utterance,
         * using a valid BCP 47 language tag.
         * [BCP47] If unset it remains unset for getting in script,
         * but will default to use the language of the html document root element and associated hierarchy.
         * This default value is computed and used when the input request opens a connection
         * to the recognition service.
         */
        get: /**
         * This attribute specifies the language of the speech synthesis for the utterance,
         * using a valid BCP 47 language tag.
         * [BCP47] If unset it remains unset for getting in script,
         * but will default to use the language of the html document root element and associated hierarchy.
         * This default value is computed and used when the input request opens a connection
         * to the recognition service.
         * @return {?}
         */
        function () {
            return this._lang || this._config.lang;
        },
        set: /**
         * @param {?} lang
         * @return {?}
         */
        function (lang) {
            this._lang = lang;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "voice", {
        /**
         * This attribute specifies the speech synthesis voice that the web application wishes to use.
         * When a SpeechSynthesisUtterance object is created this attribute must be initialized to null.
         * If, at the time of the speak() method call,
         * this attribute has been set to one of the SpeechSynthesisVoice objects returned by getVoices(),
         * then the user agent must use that voice. If this attribute is unset or null at the time of the speak()
         * method call, then the user agent must use a user agent default voice.
         * The user agent default voice should support the current language (see lang) and
         * can be a local or remote speech service and can incorporate end user choices via interfaces
         * provided by the user agent such as browser configuration parameters.
         */
        get: /**
         * This attribute specifies the speech synthesis voice that the web application wishes to use.
         * When a SpeechSynthesisUtterance object is created this attribute must be initialized to null.
         * If, at the time of the speak() method call,
         * this attribute has been set to one of the SpeechSynthesisVoice objects returned by getVoices(),
         * then the user agent must use that voice. If this attribute is unset or null at the time of the speak()
         * method call, then the user agent must use a user agent default voice.
         * The user agent default voice should support the current language (see lang) and
         * can be a local or remote speech service and can incorporate end user choices via interfaces
         * provided by the user agent such as browser configuration parameters.
         * @return {?}
         */
        function () {
            return this._voice || this._config.voice;
        },
        set: /**
         * @param {?} voice
         * @return {?}
         */
        function (voice) {
            this._voice = voice;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "volume", {
        /**
         * This attribute specifies the speaking volume for the utterance.
         * It ranges between 0 and 1 inclusive, with 0 being the lowest volume and 1 the highest volume,
         * with a default of 1. If SSML is used, this value will be overridden by prosody tags in the markup.
         */
        get: /**
         * This attribute specifies the speaking volume for the utterance.
         * It ranges between 0 and 1 inclusive, with 0 being the lowest volume and 1 the highest volume,
         * with a default of 1. If SSML is used, this value will be overridden by prosody tags in the markup.
         * @return {?}
         */
        function () {
            return this._volume || this._config.volume;
        },
        set: /**
         * @param {?} volume
         * @return {?}
         */
        function (volume) {
            this._volume = volume;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "rate", {
        /**
         * This attribute specifies the speaking rate for the utterance.
         * It is relative to the default rate for this voice.
         * 1 is the default rate supported by the speech synthesis engine or specific voice
         * (which should correspond to a normal speaking rate).
         * 2 is twice as fast, and 0.5 is half as fast. Values below 0.1 or above 10 are strictly disallowed,
         * but speech synthesis engines or specific voices may constrain the minimum and maximum rates further,
         * for example, a particular voice may not actually speak faster than 3 times normal
         * even if you specify a value larger than 3.
         * If SSML is used, this value will be overridden by prosody tags in the markup.
         */
        get: /**
         * This attribute specifies the speaking rate for the utterance.
         * It is relative to the default rate for this voice.
         * 1 is the default rate supported by the speech synthesis engine or specific voice
         * (which should correspond to a normal speaking rate).
         * 2 is twice as fast, and 0.5 is half as fast. Values below 0.1 or above 10 are strictly disallowed,
         * but speech synthesis engines or specific voices may constrain the minimum and maximum rates further,
         * for example, a particular voice may not actually speak faster than 3 times normal
         * even if you specify a value larger than 3.
         * If SSML is used, this value will be overridden by prosody tags in the markup.
         * @return {?}
         */
        function () {
            return this._rate || this._config.rate;
        },
        set: /**
         * @param {?} rate
         * @return {?}
         */
        function (rate) {
            this._rate = rate;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "pitch", {
        /**
         * This attribute specifies the speaking pitch for the utterance.
         * It ranges between 0 and 2 inclusive, with 0 being the lowest pitch and 2 the highest pitch.
         * 1 corresponds to the default pitch of the speech synthesis engine or specific voice.
         * Speech synthesis engines or voices may constrain the minimum and maximum rates further.
         * If SSML is used, this value will be overridden by prosody tags in the markup.
         */
        get: /**
         * This attribute specifies the speaking pitch for the utterance.
         * It ranges between 0 and 2 inclusive, with 0 being the lowest pitch and 2 the highest pitch.
         * 1 corresponds to the default pitch of the speech synthesis engine or specific voice.
         * Speech synthesis engines or voices may constrain the minimum and maximum rates further.
         * If SSML is used, this value will be overridden by prosody tags in the markup.
         * @return {?}
         */
        function () {
            return this._pitch || this._config.pitch;
        },
        set: /**
         * @param {?} pitch
         * @return {?}
         */
        function (pitch) {
            this._pitch = pitch;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "onstart", {
        /**
         * Fired when this utterance has begun to be spoken.
         */
        get: /**
         * Fired when this utterance has begun to be spoken.
         * @return {?}
         */
        function () {
            return this._onstart || this._config.onstart;
        },
        set: /**
         * @param {?} onstart
         * @return {?}
         */
        function (onstart) {
            this._onstart = onstart;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "onend", {
        /**
         * Fired when this utterance has completed being spoken. If this event fires,
         * the error event must not be fired for this utterance.
         */
        get: /**
         * Fired when this utterance has completed being spoken. If this event fires,
         * the error event must not be fired for this utterance.
         * @return {?}
         */
        function () {
            return this._onend || this._config.onend;
        },
        set: /**
         * @param {?} onend
         * @return {?}
         */
        function (onend) {
            this._onend = onend;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "onerror", {
        /**
         * Fired if there was an error that prevented successful speaking of this utterance.
         * If this event fires, the end event must not be fired for this utterance.
         */
        get: /**
         * Fired if there was an error that prevented successful speaking of this utterance.
         * If this event fires, the end event must not be fired for this utterance.
         * @return {?}
         */
        function () {
            return this._onerror || this._config.onerror;
        },
        set: /**
         * @param {?} onerror
         * @return {?}
         */
        function (onerror) {
            this._onerror = onerror;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "onpause", {
        /**
         * Fired when and if this utterance is paused mid-utterance.
         */
        get: /**
         * Fired when and if this utterance is paused mid-utterance.
         * @return {?}
         */
        function () {
            return this._onpause || this._config.onpause;
        },
        set: /**
         * @param {?} onpause
         * @return {?}
         */
        function (onpause) {
            this._onpause = onpause;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "onresume", {
        /**
         * Fired when and if this utterance is resumed after being paused mid-utterance.
         * Adding the utterance to the queue while the global SpeechSynthesis instance is in the paused state,
         * and then calling the resume method does not cause the resume event to be fired,
         * in this case the utterance’s start event will be called when the utterance starts.
         */
        get: /**
         * Fired when and if this utterance is resumed after being paused mid-utterance.
         * Adding the utterance to the queue while the global SpeechSynthesis instance is in the paused state,
         * and then calling the resume method does not cause the resume event to be fired,
         * in this case the utterance’s start event will be called when the utterance starts.
         * @return {?}
         */
        function () {
            return this._onresume || this._config.onresume;
        },
        set: /**
         * @param {?} onresume
         * @return {?}
         */
        function (onresume) {
            this._onresume = onresume;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "onmark", {
        /**
         * Fired when the spoken utterance reaches a named "mark" tag in SSML.
         * [SSML] The user agent must fire this event if the speech synthesis engine provides the event.
         */
        get: /**
         * Fired when the spoken utterance reaches a named "mark" tag in SSML.
         * [SSML] The user agent must fire this event if the speech synthesis engine provides the event.
         * @return {?}
         */
        function () {
            return this._onmark || this._config.onmark;
        },
        set: /**
         * @param {?} onmark
         * @return {?}
         */
        function (onmark) {
            this._onmark = onmark;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "onboundary", {
        /**
         * Fired when the spoken utterance reaches a word or sentence boundary.
         * The user agent must fire this event if the speech synthesis engine provides the event.
         */
        get: /**
         * Fired when the spoken utterance reaches a word or sentence boundary.
         * The user agent must fire this event if the speech synthesis engine provides the event.
         * @return {?}
         */
        function () {
            return this._onboundary || this._config.onboundary;
        },
        set: /**
         * @param {?} onboundary
         * @return {?}
         */
        function (onboundary) {
            this._onboundary = onboundary;
        },
        enumerable: true,
        configurable: true
    });
    /**
     * This attribute specifies the text to be synthesized and spoken for this utterance.
     * This may be either plain text or a complete, well-formed SSML document.
     * [SSML] For speech synthesis engines that do not support SSML,
     * or only support certain tags, the user agent or speech engine must strip away
     * the tags they do not support and speak the text. There may be a maximum length of the text,
     * it may be limited to 32,767 characters.
     */
    /**
     * This attribute specifies the text to be synthesized and spoken for this utterance.
     * This may be either plain text or a complete, well-formed SSML document.
     * [SSML] For speech synthesis engines that do not support SSML,
     * or only support certain tags, the user agent or speech engine must strip away
     * the tags they do not support and speak the text. There may be a maximum length of the text,
     * it may be limited to 32,767 characters.
     * @param {?} text
     * @return {?}
     */
    SpeechSynthesisUtteranceFactoryService.prototype.text = /**
     * This attribute specifies the text to be synthesized and spoken for this utterance.
     * This may be either plain text or a complete, well-formed SSML document.
     * [SSML] For speech synthesis engines that do not support SSML,
     * or only support certain tags, the user agent or speech engine must strip away
     * the tags they do not support and speak the text. There may be a maximum length of the text,
     * it may be limited to 32,767 characters.
     * @param {?} text
     * @return {?}
     */
    function (text) {
        /** @type {?} */
        var utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = this.lang;
        utterance.voice = this.voice;
        utterance.volume = this.volume;
        utterance.rate = this.rate;
        utterance.pitch = this.pitch;
        utterance.onstart = this.onstart;
        utterance.onend = this.onend;
        utterance.onerror = this.onerror;
        utterance.onpause = this.onpause;
        utterance.onresume = this.onresume;
        utterance.onmark = this.onmark;
        utterance.onboundary = this.onboundary;
        return utterance;
    };
    SpeechSynthesisUtteranceFactoryService.decorators = [
        { type: Injectable, args: [{
                    providedIn: 'root'
                },] }
    ];
    /** @nocollapse */
    SpeechSynthesisUtteranceFactoryService.ctorParameters = function () { return [
        { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [Config,] }] },
        { type: String, decorators: [{ type: Optional }, { type: Inject, args: [Lang,] }] },
        { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [Voice,] }] },
        { type: Number, decorators: [{ type: Optional }, { type: Inject, args: [Volume,] }] },
        { type: Number, decorators: [{ type: Optional }, { type: Inject, args: [Rate,] }] },
        { type: Number, decorators: [{ type: Optional }, { type: Inject, args: [Pitch,] }] },
        { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [OnStartHandler,] }] },
        { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [OnEndHandler,] }] },
        { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [OnErrorHandler,] }] },
        { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [OnPauseHandler,] }] },
        { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [OnResumeHandler,] }] },
        { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [OnMarkHandler,] }] },
        { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [OnBoundaryHandler,] }] }
    ]; };
    /** @nocollapse */ SpeechSynthesisUtteranceFactoryService.ngInjectableDef = defineInjectable({ factory: function SpeechSynthesisUtteranceFactoryService_Factory() { return new SpeechSynthesisUtteranceFactoryService(inject(Config, 8), inject(Lang, 8), inject(Voice, 8), inject(Volume, 8), inject(Rate, 8), inject(Pitch, 8), inject(OnStartHandler, 8), inject(OnEndHandler, 8), inject(OnErrorHandler, 8), inject(OnPauseHandler, 8), inject(OnResumeHandler, 8), inject(OnMarkHandler, 8), inject(OnBoundaryHandler, 8)); }, token: SpeechSynthesisUtteranceFactoryService, providedIn: "root" });
    return SpeechSynthesisUtteranceFactoryService;
}());

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
var SpeechSynthesisModule = /** @class */ (function () {
    function SpeechSynthesisModule() {
    }
    /**
     * @param {?} config
     * @return {?}
     */
    SpeechSynthesisModule.forRoot = /**
     * @param {?} config
     * @return {?}
     */
    function (config) {
        return {
            ngModule: SpeechSynthesisModule,
            providers: [
                {
                    provide: Config,
                    useValue: config,
                },
            ],
        };
    };
    SpeechSynthesisModule.decorators = [
        { type: NgModule, args: [{
                    declarations: [],
                    imports: [],
                    exports: []
                },] }
    ];
    return SpeechSynthesisModule;
}());

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
/* tslint:disable */
/** @type {?} */
var SpeechSynthesisVoice = window['SpeechSynthesisVoice'];

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */

export { Lang, Voice, Volume, Rate, Pitch, OnStartHandler, OnEndHandler, OnErrorHandler, OnPauseHandler, OnResumeHandler, OnMarkHandler, OnBoundaryHandler, Params, Config, SpeechSynthesisService, SpeechSynthesisUtteranceFactoryService, SpeechSynthesisModule, SpeechSynthesisVoice as ɵa };

//# sourceMappingURL=kamiazya-ngx-speech-synthesis.js.map