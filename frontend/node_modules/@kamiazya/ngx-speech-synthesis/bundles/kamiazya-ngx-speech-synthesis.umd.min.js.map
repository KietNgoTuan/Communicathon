{"version":3,"sources":["ng://@kamiazya/ngx-speech-synthesis/lib/configs.ts","ng://@kamiazya/ngx-speech-synthesis/lib/services/speech-synthesis.service.ts","ng://@kamiazya/ngx-speech-synthesis/lib/services/speech-synthesis-utterance-factory.service.ts","ng://@kamiazya/ngx-speech-synthesis/lib/speech-synthesis.module.ts","ng://@kamiazya/ngx-speech-synthesis/lib/adapters/adapter.ts"],"names":["Lang","InjectionToken","Voice","Volume","Rate","Pitch","OnStartHandler","OnEndHandler","OnErrorHandler","OnPauseHandler","OnResumeHandler","OnMarkHandler","OnBoundaryHandler","Params","Config","SpeechSynthesisService","this","internal","window","speechSynthesis","Object","defineProperty","prototype","pending","speaking","paused","handler","onvoiceschanged","speak","utterance","cancel","pause","resume","getVoices","Injectable","args","providedIn","SpeechSynthesisUtteranceFactoryService","config","lang","voice","volume","rate","pitch","onstart","onend","onerror","onpause","onresume","onmark","onboundary","_this","_config","_lang","addEventListener","_voice","find","v","name","_volume","_rate","_pitch","_onstart","_onend","_onerror","_onpause","_onresume","_onmark","_onboundary","text","SpeechSynthesisUtterance","Optional","type","Inject","SpeechSynthesisModule","forRoot","ngModule","providers","provide","useValue","NgModule","declarations","imports","exports","SpeechSynthesisVoice"],"mappings":"qUA0BA,IAAaA,EAAoB,IAAIC,EAAAA,eAAuB,yBAC/CC,EAAoB,IAAID,EAAAA,eAA8C,0BACtEE,EAAoB,IAAIF,EAAAA,eAAuB,2BAC/CG,EAAoB,IAAIH,EAAAA,eAAwB,yBAChDI,EAAoB,IAAIJ,EAAAA,eAAuB,0BAC/CK,EAAoB,IAAIL,EAAAA,eAAqD,4BAC7EM,EAAoB,IAAIN,EAAAA,eAAqD,0BAC7EO,EAAoB,IAAIP,EAAAA,eAA0D,4BAClFQ,EAAoB,IAAIR,EAAAA,eAAqD,4BAC7ES,EAAoB,IAAIT,EAAAA,eAAqD,6BAC7EU,EAAoB,IAAIV,EAAAA,eAAqD,2BAC7EW,EAAoB,IAAIX,EAAAA,eAAqD,+BAC7EY,EAAoB,IAAIZ,EAAAA,eAA+C,2BACvEa,EAAoB,IAAIb,EAAAA,eAA+C,2BCvCpFc,EAAA,WAeE,SAAAA,IACEC,KAAKC,SAAWC,OAAOC,uBASzBC,OAAAC,eAAIN,EAAAO,UAAA,UAAO,KAAX,WACE,OAAON,KAAKC,SAASM,yCAUvBH,OAAAC,eAAIN,EAAAO,UAAA,WAAQ,KAAZ,WACE,OAAON,KAAKC,SAASO,0CAUvBJ,OAAAC,eAAIN,EAAAO,UAAA,SAAM,KAAV,WACE,OAAON,KAAKC,SAASQ,wCASvBL,OAAAC,eAAIN,EAAAO,UAAA,kBAAe,KAAnB,SAAoBI,GAClBV,KAAKC,SAASU,gBAAkBD,mCAmB3BX,EAAAO,UAAAM,MAAP,SAAaC,GACXb,KAAKC,SAASW,MAAMC,IAQfd,EAAAO,UAAAQ,OAAP,WACEd,KAAKC,SAASa,UAQTf,EAAAO,UAAAS,MAAP,WACEf,KAAKC,SAASc,SAUThB,EAAAO,UAAAU,OAAP,WACEhB,KAAKC,SAASe,UAUTjB,EAAAO,UAAAW,UAAP,WACE,OAAOjB,KAAKC,SAASgB,iCAlHxBC,EAAAA,WAAUC,KAAA,CAAC,CACVC,WAAY,sJALd,GCsBAC,EAAA,WAyBE,SAAAA,EAEEC,EAWAC,EAcAC,EAQAC,EAcAC,EAUAC,EAMAC,EAOAC,EAOAC,EAMAC,EASAC,EAOAC,EAOAC,GA5GF,IAAAC,EAAAnC,KA+GEA,KAAKC,SAAWC,OAAOC,gBACvBH,KAAKoC,QAAUd,EACftB,KAAKqC,MAAQd,EACQ,iBAAVC,EACTxB,KAAKC,SACFqC,iBAAiB,gBAAiB,WACjCH,EAAKI,OAASJ,EAAKlC,SAChBgB,YAAYuB,KAAK,SAAAC,GAAK,OAAAA,EAAEC,OAASlB,MAGxCxB,KAAKuC,OAASf,EAEhBxB,KAAK2C,QAAUlB,EACfzB,KAAK4C,MAAQlB,EACb1B,KAAK6C,OAASlB,EACd3B,KAAK8C,SAAWlB,EAChB5B,KAAK+C,OAASlB,EACd7B,KAAKgD,SAAWlB,EAChB9B,KAAKiD,SAAWlB,EAChB/B,KAAKkD,UAAYlB,EACjBhC,KAAKmD,QAAUlB,EACfjC,KAAKoD,YAAclB,SAWrB9B,OAAAC,eAAIgB,EAAAf,UAAA,OAAI,KAAR,WACE,OAAON,KAAKqC,OAASrC,KAAKoC,QAAQb,UAGpC,SAASA,GACPvB,KAAKqC,MAAQd,mCAcfnB,OAAAC,eAAIgB,EAAAf,UAAA,QAAK,KAAT,WACE,OAAON,KAAKuC,QAAUvC,KAAKoC,QAAQZ,WAErC,SAAUA,GACRxB,KAAKuC,OAASf,mCAQhBpB,OAAAC,eAAIgB,EAAAf,UAAA,SAAM,KAAV,WACE,OAAON,KAAK2C,SAAW3C,KAAKoC,QAAQX,YAGtC,SAAWA,GACTzB,KAAK2C,QAAUlB,mCAcjBrB,OAAAC,eAAIgB,EAAAf,UAAA,OAAI,KAAR,WACE,OAAON,KAAK4C,OAAS5C,KAAKoC,QAAQV,UAGpC,SAASA,GACP1B,KAAK4C,MAAQlB,mCAUftB,OAAAC,eAAIgB,EAAAf,UAAA,QAAK,KAAT,WACE,OAAON,KAAK6C,QAAU7C,KAAKoC,QAAQT,WAGrC,SAAUA,GACR3B,KAAK6C,OAASlB,mCAMhBvB,OAAAC,eAAIgB,EAAAf,UAAA,UAAO,KAAX,WACE,OAAON,KAAK8C,UAAY9C,KAAKoC,QAAQR,aAGvC,SAAYA,GACV5B,KAAK8C,SAAWlB,mCAOlBxB,OAAAC,eAAIgB,EAAAf,UAAA,QAAK,KAAT,WACE,OAAON,KAAK+C,QAAU/C,KAAKoC,QAAQP,WAGrC,SAAUA,GACR7B,KAAK+C,OAASlB,mCAOhBzB,OAAAC,eAAIgB,EAAAf,UAAA,UAAO,KAAX,WACE,OAAON,KAAKgD,UAAYhD,KAAKoC,QAAQN,aAGvC,SAAYA,GACV9B,KAAKgD,SAAWlB,mCAMlB1B,OAAAC,eAAIgB,EAAAf,UAAA,UAAO,KAAX,WACE,OAAON,KAAKiD,UAAYjD,KAAKoC,QAAQL,aAGvC,SAAYA,GACV/B,KAAKiD,SAAWlB,mCASlB3B,OAAAC,eAAIgB,EAAAf,UAAA,WAAQ,KAAZ,WACE,OAAON,KAAKkD,WAAalD,KAAKoC,QAAQJ,cAGxC,SAAaA,GACXhC,KAAKkD,UAAYlB,mCAOnB5B,OAAAC,eAAIgB,EAAAf,UAAA,SAAM,KAAV,WACE,OAAON,KAAKmD,SAAWnD,KAAKoC,QAAQH,YAGtC,SAAWA,GACTjC,KAAKmD,QAAUlB,mCAOjB7B,OAAAC,eAAIgB,EAAAf,UAAA,aAAU,KAAd,WACE,OAAON,KAAKoD,aAAepD,KAAKoC,QAAQF,gBAG1C,SAAeA,GACblC,KAAKoD,YAAclB,mCAWdb,EAAAf,UAAA+C,KAAP,SAAYA,OACJxC,EAAY,IAAIyC,yBAAyBD,GAe/C,OAbAxC,EAAUU,KAAavB,KAAKuB,KAC5BV,EAAUW,MAAaxB,KAAKwB,MAC5BX,EAAUY,OAAazB,KAAKyB,OAC5BZ,EAAUa,KAAa1B,KAAK0B,KAC5Bb,EAAUc,MAAa3B,KAAK2B,MAC5Bd,EAAUe,QAAa5B,KAAK4B,QAC5Bf,EAAUgB,MAAa7B,KAAK6B,MAC5BhB,EAAUiB,QAAa9B,KAAK8B,QAC5BjB,EAAUkB,QAAa/B,KAAK+B,QAC5BlB,EAAUmB,SAAahC,KAAKgC,SAC5BnB,EAAUoB,OAAajC,KAAKiC,OAC5BpB,EAAUqB,WAAalC,KAAKkC,WAErBrB,uBA7VVK,EAAAA,WAAUC,KAAA,CAAC,CACVC,WAAY,gFAyBTmC,EAAAA,UAAQ,CAAAC,KAAIC,EAAAA,OAAMtC,KAAA,CAACrB,qCAGnByD,EAAAA,UAAQ,CAAAC,KAAIC,EAAAA,OAAMtC,KAAA,CAACnC,wCAWnBuE,EAAAA,UAAQ,CAAAC,KAAIC,EAAAA,OAAMtC,KAAA,CAACjC,qCAcnBqE,EAAAA,UAAQ,CAAAC,KAAIC,EAAAA,OAAMtC,KAAA,CAAChC,qCAQnBoE,EAAAA,UAAQ,CAAAC,KAAIC,EAAAA,OAAMtC,KAAA,CAAC/B,qCAcnBmE,EAAAA,UAAQ,CAAAC,KAAIC,EAAAA,OAAMtC,KAAA,CAAC9B,wCAUnBkE,EAAAA,UAAQ,CAAAC,KAAIC,EAAAA,OAAMtC,KAAA,CAAC7B,wCAMnBiE,EAAAA,UAAQ,CAAAC,KAAIC,EAAAA,OAAMtC,KAAA,CAAC5B,wCAOnBgE,EAAAA,UAAQ,CAAAC,KAAIC,EAAAA,OAAMtC,KAAA,CAAC3B,wCAOnB+D,EAAAA,UAAQ,CAAAC,KAAIC,EAAAA,OAAMtC,KAAA,CAAC1B,wCAMnB8D,EAAAA,UAAQ,CAAAC,KAAIC,EAAAA,OAAMtC,KAAA,CAACzB,wCASnB6D,EAAAA,UAAQ,CAAAC,KAAIC,EAAAA,OAAMtC,KAAA,CAACxB,wCAOnB4D,EAAAA,UAAQ,CAAAC,KAAIC,EAAAA,OAAMtC,KAAA,CAACvB,oSAhIxB,GCtBA8D,EAAA,WAGA,SAAAA,KAkBA,OAXSA,EAAAC,QAAP,SAAerC,GACb,MAAO,CACLsC,SAAUF,EACVG,UAAW,CACT,CACEC,QAAShE,EACTiE,SAAUzC,0BAbnB0C,EAAAA,SAAQ7C,KAAA,CAAC,CACR8C,aAAc,GACdC,QAAS,GACTC,QAAS,OAeXT,EArBA,GCCWU,EAA6ClE,OAA6B","sourcesContent":["import { InjectionToken } from '@angular/core';\n\nexport type SpeechSynthesisUtteranceEventHandler = ((this: SpeechSynthesisUtterance, ev: SpeechSynthesisEvent) => any) | null;\n\nexport type SpeechSynthesisUtteranceErrorEventHandler = ((this: SpeechSynthesisUtterance, ev: SpeechSynthesisErrorEvent) => any) | null;\n\nexport interface SpeechSynthesisUtteranceParams {\n  lang?: string;\n  pitch?: number;\n  rate?: number;\n  text?: string;\n  voice?: SpeechSynthesisVoice;\n  volume?: number;\n}\n\nexport interface SpeechSynthesisUtteranceConfig extends SpeechSynthesisUtteranceParams {\n  onboundary?: SpeechSynthesisUtteranceEventHandler;\n  onend?: SpeechSynthesisUtteranceEventHandler;\n  onerror?: SpeechSynthesisUtteranceErrorEventHandler;\n  onmark?: SpeechSynthesisUtteranceEventHandler;\n  onpause?: SpeechSynthesisUtteranceEventHandler;\n  onresume?: SpeechSynthesisUtteranceEventHandler;\n  onstart?: SpeechSynthesisUtteranceEventHandler;\n}\n\n\nexport const Lang              = new InjectionToken<string>('speech-synthesis.lang');\nexport const Voice             = new InjectionToken<string | SpeechSynthesisVoice>('speech-synthesis.voice');\nexport const Volume            = new InjectionToken<number>('speech-synthesis.volume');\nexport const Rate              = new InjectionToken<boolean>('speech-synthesis.rate');\nexport const Pitch             = new InjectionToken<number>('speech-synthesis.pitch');\nexport const OnStartHandler    = new InjectionToken<SpeechSynthesisUtteranceEventHandler>('speech-synthesis.onstart');\nexport const OnEndHandler      = new InjectionToken<SpeechSynthesisUtteranceEventHandler>('speech-synthesis.onend');\nexport const OnErrorHandler    = new InjectionToken<SpeechSynthesisUtteranceErrorEventHandler>('speech-synthesis.onerror');\nexport const OnPauseHandler    = new InjectionToken<SpeechSynthesisUtteranceEventHandler>('speech-synthesis.onpause');\nexport const OnResumeHandler   = new InjectionToken<SpeechSynthesisUtteranceEventHandler>('speech-synthesis.onresume');\nexport const OnMarkHandler     = new InjectionToken<SpeechSynthesisUtteranceEventHandler>('speech-synthesis.onmark');\nexport const OnBoundaryHandler = new InjectionToken<SpeechSynthesisUtteranceEventHandler>('speech-synthesis.onboundary');\nexport const Params            = new InjectionToken<SpeechSynthesisUtteranceParams>('speech-synthesis.params');\nexport const Config            = new InjectionToken<SpeechSynthesisUtteranceConfig>('speech-synthesis.config');\n","import { Injectable } from '@angular/core';\n\ntype VoicesChangedEventHandler = ((this: SpeechSynthesis, ev: Event) => any) | null;\n\n@Injectable({\n  providedIn: 'root'\n})\nexport class SpeechSynthesisService {\n\n  /**\n   * If SpeechSynthesis API is supported\n   * by the browser instance will be included.\n   */\n  private internal: SpeechSynthesis;\n\n  constructor() {\n    this.internal = window.speechSynthesis;\n  }\n\n\n  /**\n   * This attribute is true if the queue for\n   * the global SpeechSynthesis instance contains any utterances\n   * which have not started speaking.\n   */\n  get pending(): boolean {\n    return this.internal.pending;\n  }\n\n  /**\n   * This attribute is true if an utterance is being spoken.\n   * Specifically if an utterance has begun being spoken\n   * and has not completed being spoken.\n   * This is independent of whether the global SpeechSynthesis instance is\n   * in the paused state.\n   */\n  get speaking(): boolean {\n    return this.internal.speaking;\n  }\n\n  /**\n   * This attribute is true when the global SpeechSynthesis instance is\n   * in the paused state.\n   * This state is independent of whether anything is in the queue.\n   * The default state of a the global SpeechSynthesis instance\n   * for a new window is the non-paused state.\n   */\n  get paused(): boolean {\n    return this.internal.paused;\n  }\n\n  /**\n   * Fired when the contents of the SpeechSynthesisVoiceList,\n   * that the getVoices method will return, have changed.\n   * Examples include: server-side synthesis where the list is determined asynchronously,\n   * or when client-side voices are installed/uninstalled.\n   */\n  set onvoiceschanged(handler: VoicesChangedEventHandler) {\n    this.internal.onvoiceschanged = handler;\n  }\n\n  /**\n   * This method appends the SpeechSynthesisUtterance object utterance\n   * to the end of the queue for the global SpeechSynthesis instance.\n   * It does not change the paused state of the SpeechSynthesis instance.\n   * If the SpeechSynthesis instance is paused, it remains paused.\n   * If it is not paused and no other utterances are in the queue,\n   * then this utterance is spoken immediately, else this utterance is queued\n   * to begin speaking after the other utterances in the queue have been spoken.\n   * If changes are made to the SpeechSynthesisUtterance object after calling\n   * this method and prior to the corresponding end or error event,\n   * it is not defined whether those changes will affect what is spoken,\n   * and those changes may cause an error to be returned.\n   * The SpeechSynthesis object takes exclusive ownership of the SpeechSynthesisUtterance object.\n   * Passing it as a speak() argument to another SpeechSynthesis object should throw an exception.\n   * (For example, two frames may have the same origin and each will contain a SpeechSynthesis object.)\n   */\n  public speak(utterance: SpeechSynthesisUtterance): void {\n    this.internal.speak(utterance);\n  }\n\n  /**\n   * This method removes all utterances from the queue.\n   * If an utterance is being spoken, speaking ceases immediately.\n   * This method does not change the paused state of the global SpeechSynthesis instance.\n   */\n  public cancel(): void {\n    this.internal.cancel();\n  }\n\n  /**\n   * This method puts the global SpeechSynthesis instance into the paused state.\n   * If an utterance was being spoken, it pauses mid-utterance.\n   * (If called when the SpeechSynthesis instance was already in the paused state, it does nothing.)\n   */\n  public pause(): void {\n    this.internal.pause();\n  }\n\n  /**\n   * This method puts the global SpeechSynthesis instance into the non-paused state.\n   * If an utterance was speaking, it continues speaking the utterance\n   * at the point at which it was paused, else it begins speaking\n   * the next utterance in the queue (if any).\n   * (If called when the SpeechSynthesis instance was already in the non-paused state, it does nothing.)\n   */\n  public resume(): void {\n    this.internal.resume();\n  }\n\n  /**\n   * This method returns the available voices.\n   * It is user agent dependent which voices are available.\n   * If there are no voices available, or if the the list of available voices\n   * is not yet known (for example: server-side synthesis where the list is determined asynchronously),\n   * then this method must return a SpeechSynthesisVoiceList of length zero.\n   */\n  public getVoices(): SpeechSynthesisVoice[] {\n    return this.internal.getVoices();\n  }\n}\n","import { Injectable, Optional, Inject } from '@angular/core';\n\nimport {\n  Lang,\n  Voice,\n  Volume,\n  Rate,\n  Pitch,\n  OnStartHandler,\n  OnEndHandler,\n  OnErrorHandler,\n  OnPauseHandler,\n  OnResumeHandler,\n  OnMarkHandler,\n  OnBoundaryHandler,\n  SpeechSynthesisUtteranceEventHandler,\n  SpeechSynthesisUtteranceConfig,\n  Config,\n  SpeechSynthesisUtteranceErrorEventHandler,\n} from '../configs';\nimport { SpeechSynthesisVoice } from '../adapters/adapter';\n/** @dynamic */\n@Injectable({\n  providedIn: 'root'\n})\nexport class SpeechSynthesisUtteranceFactoryService {\n  private _config?: SpeechSynthesisUtteranceConfig;\n  private _lang?: string;\n  private _voice?: SpeechSynthesisVoice;\n  private _volume?: number;\n  private _rate?: number;\n  private _pitch?: number;\n  private _onstart?: SpeechSynthesisUtteranceEventHandler;\n  private _onend?: SpeechSynthesisUtteranceEventHandler;\n  private _onerror?: SpeechSynthesisUtteranceErrorEventHandler;\n  private _onpause?: SpeechSynthesisUtteranceEventHandler;\n  private _onresume?: SpeechSynthesisUtteranceEventHandler;\n  private _onmark?: SpeechSynthesisUtteranceEventHandler;\n  private _onboundary?: SpeechSynthesisUtteranceEventHandler;\n\n\n  /**\n   * If SpeechSynthesis API is supported\n   * by the browser instance will be included.\n   */\n  private internal: SpeechSynthesis;\n\n  constructor(\n    @Optional() @Inject(Config)\n    config?: SpeechSynthesisUtteranceConfig,\n\n    @Optional() @Inject(Lang)\n    /**\n     * This attribute specifies the language of the speech synthesis for the utterance,\n     * using a valid BCP 47 language tag.\n     * [BCP47] If unset it remains unset for getting in script,\n     * but will default to use the language of the html document root element and associated hierarchy.\n     * This default value is computed and used when the input request opens a connection\n     * to the recognition service.\n     */\n    lang?: string,\n\n    @Optional() @Inject(Voice)\n    /**\n     * This attribute specifies the speech synthesis voice that the web application wishes to use.\n     * When a SpeechSynthesisUtterance object is created this attribute must be initialized to null.\n     * If, at the time of the speak() method call,\n     * this attribute has been set to one of the SpeechSynthesisVoice objects returned by getVoices(),\n     * then the user agent must use that voice. If this attribute is unset or null at the time of the speak()\n     * method call, then the user agent must use a user agent default voice.\n     * The user agent default voice should support the current language (see lang) and\n     * can be a local or remote speech service and can incorporate end user choices via interfaces\n     * provided by the user agent such as browser configuration parameters.\n     */\n    voice?: SpeechSynthesisVoice | string,\n\n    @Optional() @Inject(Volume)\n    /**\n     * This attribute specifies the speaking volume for the utterance.\n     * It ranges between 0 and 1 inclusive, with 0 being the lowest volume and 1 the highest volume,\n     * with a default of 1. If SSML is used, this value will be overridden by prosody tags in the markup.\n     */\n    volume?: number,\n\n    @Optional() @Inject(Rate)\n    /**\n     * This attribute specifies the speaking rate for the utterance.\n     * It is relative to the default rate for this voice.\n     * 1 is the default rate supported by the speech synthesis engine or specific voice\n     * (which should correspond to a normal speaking rate).\n     * 2 is twice as fast, and 0.5 is half as fast. Values below 0.1 or above 10 are strictly disallowed,\n     * but speech synthesis engines or specific voices may constrain the minimum and maximum rates further,\n     * for example, a particular voice may not actually speak faster than 3 times normal\n     * even if you specify a value larger than 3.\n     * If SSML is used, this value will be overridden by prosody tags in the markup.\n     */\n    rate?: number,\n\n    @Optional() @Inject(Pitch)\n    /**\n     * This attribute specifies the speaking pitch for the utterance.\n     * It ranges between 0 and 2 inclusive, with 0 being the lowest pitch and 2 the highest pitch.\n     * 1 corresponds to the default pitch of the speech synthesis engine or specific voice.\n     * Speech synthesis engines or voices may constrain the minimum and maximum rates further.\n     * If SSML is used, this value will be overridden by prosody tags in the markup.\n     */\n    pitch?: number,\n\n    @Optional() @Inject(OnStartHandler)\n    /**\n     * Fired when this utterance has begun to be spoken.\n     */\n    onstart?: SpeechSynthesisUtteranceEventHandler,\n\n    @Optional() @Inject(OnEndHandler)\n    /**\n     * Fired when this utterance has completed being spoken. If this event fires,\n     * the error event must not be fired for this utterance.\n     */\n    onend?: SpeechSynthesisUtteranceEventHandler,\n\n    @Optional() @Inject(OnErrorHandler)\n    /**\n     * Fired if there was an error that prevented successful speaking of this utterance.\n     * If this event fires, the end event must not be fired for this utterance.\n     */\n    onerror?: SpeechSynthesisUtteranceErrorEventHandler,\n\n    @Optional() @Inject(OnPauseHandler)\n    /**\n     * Fired when and if this utterance is paused mid-utterance.\n     */\n    onpause?: SpeechSynthesisUtteranceEventHandler,\n\n    @Optional() @Inject(OnResumeHandler)\n    /**\n     * Fired when and if this utterance is resumed after being paused mid-utterance.\n     * Adding the utterance to the queue while the global SpeechSynthesis instance is in the paused state,\n     * and then calling the resume method does not cause the resume event to be fired,\n     * in this case the utteranceâs start event will be called when the utterance starts.\n     */\n    onresume?: SpeechSynthesisUtteranceEventHandler,\n\n    @Optional() @Inject(OnMarkHandler)\n    /**\n     * Fired when the spoken utterance reaches a named \"mark\" tag in SSML.\n     * [SSML] The user agent must fire this event if the speech synthesis engine provides the event.\n     */\n    onmark?: SpeechSynthesisUtteranceEventHandler,\n\n    @Optional() @Inject(OnBoundaryHandler)\n    /**\n     * Fired when the spoken utterance reaches a word or sentence boundary.\n     * The user agent must fire this event if the speech synthesis engine provides the event.\n     */\n    onboundary?: SpeechSynthesisUtteranceEventHandler,\n\n  ) {\n    this.internal = window.speechSynthesis;\n    this._config = config;\n    this._lang = lang;\n    if (typeof voice === 'string') {\n      this.internal\n        .addEventListener('voiceschanged', () => {\n          this._voice = this.internal\n            .getVoices().find(v => v.name === voice);\n        });\n    } else {\n      this._voice = voice;\n    }\n    this._volume = volume;\n    this._rate = rate;\n    this._pitch = pitch;\n    this._onstart = onstart;\n    this._onend = onend;\n    this._onerror = onerror;\n    this._onpause = onpause;\n    this._onresume = onresume;\n    this._onmark = onmark;\n    this._onboundary = onboundary;\n  }\n\n  /**\n   * This attribute specifies the language of the speech synthesis for the utterance,\n   * using a valid BCP 47 language tag.\n   * [BCP47] If unset it remains unset for getting in script,\n   * but will default to use the language of the html document root element and associated hierarchy.\n   * This default value is computed and used when the input request opens a connection\n   * to the recognition service.\n   */\n  get lang(): string {\n    return this._lang || this._config.lang;\n  }\n\n  set lang(lang: string) {\n    this._lang = lang;\n  }\n\n  /**\n   * This attribute specifies the speech synthesis voice that the web application wishes to use.\n   * When a SpeechSynthesisUtterance object is created this attribute must be initialized to null.\n   * If, at the time of the speak() method call,\n   * this attribute has been set to one of the SpeechSynthesisVoice objects returned by getVoices(),\n   * then the user agent must use that voice. If this attribute is unset or null at the time of the speak()\n   * method call, then the user agent must use a user agent default voice.\n   * The user agent default voice should support the current language (see lang) and\n   * can be a local or remote speech service and can incorporate end user choices via interfaces\n   * provided by the user agent such as browser configuration parameters.\n   */\n  get voice(): SpeechSynthesisVoice {\n    return this._voice || this._config.voice;\n  }\n  set voice(voice: SpeechSynthesisVoice) {\n    this._voice = voice;\n  }\n\n  /**\n   * This attribute specifies the speaking volume for the utterance.\n   * It ranges between 0 and 1 inclusive, with 0 being the lowest volume and 1 the highest volume,\n   * with a default of 1. If SSML is used, this value will be overridden by prosody tags in the markup.\n   */\n  get volume(): number {\n    return this._volume || this._config.volume;\n  }\n\n  set volume(volume: number) {\n    this._volume = volume;\n  }\n\n  /**\n   * This attribute specifies the speaking rate for the utterance.\n   * It is relative to the default rate for this voice.\n   * 1 is the default rate supported by the speech synthesis engine or specific voice\n   * (which should correspond to a normal speaking rate).\n   * 2 is twice as fast, and 0.5 is half as fast. Values below 0.1 or above 10 are strictly disallowed,\n   * but speech synthesis engines or specific voices may constrain the minimum and maximum rates further,\n   * for example, a particular voice may not actually speak faster than 3 times normal\n   * even if you specify a value larger than 3.\n   * If SSML is used, this value will be overridden by prosody tags in the markup.\n   */\n  get rate(): number {\n    return this._rate || this._config.rate;\n  }\n\n  set rate(rate: number) {\n    this._rate = rate;\n  }\n\n  /**\n   * This attribute specifies the speaking pitch for the utterance.\n   * It ranges between 0 and 2 inclusive, with 0 being the lowest pitch and 2 the highest pitch.\n   * 1 corresponds to the default pitch of the speech synthesis engine or specific voice.\n   * Speech synthesis engines or voices may constrain the minimum and maximum rates further.\n   * If SSML is used, this value will be overridden by prosody tags in the markup.\n   */\n  get pitch(): number {\n    return this._pitch || this._config.pitch;\n  }\n\n  set pitch(pitch: number) {\n    this._pitch = pitch;\n  }\n\n  /**\n   * Fired when this utterance has begun to be spoken.\n   */\n  get onstart(): SpeechSynthesisUtteranceEventHandler {\n    return this._onstart || this._config.onstart;\n  }\n\n  set onstart(onstart: SpeechSynthesisUtteranceEventHandler) {\n    this._onstart = onstart;\n  }\n\n  /**\n   * Fired when this utterance has completed being spoken. If this event fires,\n   * the error event must not be fired for this utterance.\n   */\n  get onend(): SpeechSynthesisUtteranceEventHandler {\n    return this._onend || this._config.onend;\n  }\n\n  set onend(onend: SpeechSynthesisUtteranceEventHandler) {\n    this._onend = onend;\n  }\n\n  /**\n   * Fired if there was an error that prevented successful speaking of this utterance.\n   * If this event fires, the end event must not be fired for this utterance.\n   */\n  get onerror(): SpeechSynthesisUtteranceErrorEventHandler {\n    return this._onerror || this._config.onerror;\n  }\n\n  set onerror(onerror: SpeechSynthesisUtteranceErrorEventHandler) {\n    this._onerror = onerror;\n  }\n\n  /**\n   * Fired when and if this utterance is paused mid-utterance.\n   */\n  get onpause(): SpeechSynthesisUtteranceEventHandler {\n    return this._onpause || this._config.onpause;\n  }\n\n  set onpause(onpause: SpeechSynthesisUtteranceEventHandler) {\n    this._onpause = onpause;\n  }\n\n  /**\n   * Fired when and if this utterance is resumed after being paused mid-utterance.\n   * Adding the utterance to the queue while the global SpeechSynthesis instance is in the paused state,\n   * and then calling the resume method does not cause the resume event to be fired,\n   * in this case the utteranceâs start event will be called when the utterance starts.\n   */\n  get onresume(): SpeechSynthesisUtteranceEventHandler {\n    return this._onresume || this._config.onresume;\n  }\n\n  set onresume(onresume: SpeechSynthesisUtteranceEventHandler) {\n    this._onresume = onresume;\n  }\n\n  /**\n   * Fired when the spoken utterance reaches a named \"mark\" tag in SSML.\n   * [SSML] The user agent must fire this event if the speech synthesis engine provides the event.\n   */\n  get onmark(): SpeechSynthesisUtteranceEventHandler {\n    return this._onmark || this._config.onmark;\n  }\n\n  set onmark(onmark: SpeechSynthesisUtteranceEventHandler) {\n    this._onmark = onmark;\n  }\n\n  /**\n   * Fired when the spoken utterance reaches a word or sentence boundary.\n   * The user agent must fire this event if the speech synthesis engine provides the event.\n   */\n  get onboundary(): SpeechSynthesisUtteranceEventHandler {\n    return this._onboundary || this._config.onboundary;\n  }\n\n  set onboundary(onboundary: SpeechSynthesisUtteranceEventHandler) {\n    this._onboundary = onboundary;\n  }\n\n  /**\n   * This attribute specifies the text to be synthesized and spoken for this utterance.\n   * This may be either plain text or a complete, well-formed SSML document.\n   * [SSML] For speech synthesis engines that do not support SSML,\n   * or only support certain tags, the user agent or speech engine must strip away\n   * the tags they do not support and speak the text. There may be a maximum length of the text,\n   * it may be limited to 32,767 characters.\n   */\n  public text(text: string): SpeechSynthesisUtterance {\n    const utterance = new SpeechSynthesisUtterance(text);\n\n    utterance.lang       = this.lang;\n    utterance.voice      = this.voice;\n    utterance.volume     = this.volume;\n    utterance.rate       = this.rate;\n    utterance.pitch      = this.pitch;\n    utterance.onstart    = this.onstart;\n    utterance.onend      = this.onend;\n    utterance.onerror    = this.onerror;\n    utterance.onpause    = this.onpause;\n    utterance.onresume   = this.onresume;\n    utterance.onmark     = this.onmark;\n    utterance.onboundary = this.onboundary;\n\n    return utterance;\n  }\n}\n","import { NgModule, ModuleWithProviders } from '@angular/core';\nimport { SpeechSynthesisUtteranceConfig, Config } from './configs';\n\n@NgModule({\n  declarations: [],\n  imports: [],\n  exports: []\n})\nexport class SpeechSynthesisModule {\n\n  static forRoot(config: SpeechSynthesisUtteranceConfig): ModuleWithProviders {\n    return {\n      ngModule: SpeechSynthesisModule,\n      providers: [\n        {\n          provide: Config,\n          useValue: config,\n        },\n      ],\n    };\n  }\n}\n","/* tslint:disable */\nexport var SpeechSynthesisVoice: SpeechSynthesisVoice = window['SpeechSynthesisVoice'];\n"]}