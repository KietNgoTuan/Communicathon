{"version":3,"file":"kamiazya-ngx-speech-synthesis.js.map","sources":["ng://@kamiazya/ngx-speech-synthesis/lib/configs.ts","ng://@kamiazya/ngx-speech-synthesis/lib/services/speech-synthesis.service.ts","ng://@kamiazya/ngx-speech-synthesis/lib/services/speech-synthesis-utterance-factory.service.ts","ng://@kamiazya/ngx-speech-synthesis/lib/speech-synthesis.module.ts","ng://@kamiazya/ngx-speech-synthesis/lib/adapters/adapter.ts"],"sourcesContent":["import { InjectionToken } from '@angular/core';\n\nexport type SpeechSynthesisUtteranceEventHandler = ((this: SpeechSynthesisUtterance, ev: SpeechSynthesisEvent) => any) | null;\n\nexport type SpeechSynthesisUtteranceErrorEventHandler = ((this: SpeechSynthesisUtterance, ev: SpeechSynthesisErrorEvent) => any) | null;\n\nexport interface SpeechSynthesisUtteranceParams {\n  lang?: string;\n  pitch?: number;\n  rate?: number;\n  text?: string;\n  voice?: SpeechSynthesisVoice;\n  volume?: number;\n}\n\nexport interface SpeechSynthesisUtteranceConfig extends SpeechSynthesisUtteranceParams {\n  onboundary?: SpeechSynthesisUtteranceEventHandler;\n  onend?: SpeechSynthesisUtteranceEventHandler;\n  onerror?: SpeechSynthesisUtteranceErrorEventHandler;\n  onmark?: SpeechSynthesisUtteranceEventHandler;\n  onpause?: SpeechSynthesisUtteranceEventHandler;\n  onresume?: SpeechSynthesisUtteranceEventHandler;\n  onstart?: SpeechSynthesisUtteranceEventHandler;\n}\n\n\nexport const Lang              = new InjectionToken<string>('speech-synthesis.lang');\nexport const Voice             = new InjectionToken<string | SpeechSynthesisVoice>('speech-synthesis.voice');\nexport const Volume            = new InjectionToken<number>('speech-synthesis.volume');\nexport const Rate              = new InjectionToken<boolean>('speech-synthesis.rate');\nexport const Pitch             = new InjectionToken<number>('speech-synthesis.pitch');\nexport const OnStartHandler    = new InjectionToken<SpeechSynthesisUtteranceEventHandler>('speech-synthesis.onstart');\nexport const OnEndHandler      = new InjectionToken<SpeechSynthesisUtteranceEventHandler>('speech-synthesis.onend');\nexport const OnErrorHandler    = new InjectionToken<SpeechSynthesisUtteranceErrorEventHandler>('speech-synthesis.onerror');\nexport const OnPauseHandler    = new InjectionToken<SpeechSynthesisUtteranceEventHandler>('speech-synthesis.onpause');\nexport const OnResumeHandler   = new InjectionToken<SpeechSynthesisUtteranceEventHandler>('speech-synthesis.onresume');\nexport const OnMarkHandler     = new InjectionToken<SpeechSynthesisUtteranceEventHandler>('speech-synthesis.onmark');\nexport const OnBoundaryHandler = new InjectionToken<SpeechSynthesisUtteranceEventHandler>('speech-synthesis.onboundary');\nexport const Params            = new InjectionToken<SpeechSynthesisUtteranceParams>('speech-synthesis.params');\nexport const Config            = new InjectionToken<SpeechSynthesisUtteranceConfig>('speech-synthesis.config');\n","import { Injectable } from '@angular/core';\n\ntype VoicesChangedEventHandler = ((this: SpeechSynthesis, ev: Event) => any) | null;\n\n@Injectable({\n  providedIn: 'root'\n})\nexport class SpeechSynthesisService {\n\n  /**\n   * If SpeechSynthesis API is supported\n   * by the browser instance will be included.\n   */\n  private internal: SpeechSynthesis;\n\n  constructor() {\n    this.internal = window.speechSynthesis;\n  }\n\n\n  /**\n   * This attribute is true if the queue for\n   * the global SpeechSynthesis instance contains any utterances\n   * which have not started speaking.\n   */\n  get pending(): boolean {\n    return this.internal.pending;\n  }\n\n  /**\n   * This attribute is true if an utterance is being spoken.\n   * Specifically if an utterance has begun being spoken\n   * and has not completed being spoken.\n   * This is independent of whether the global SpeechSynthesis instance is\n   * in the paused state.\n   */\n  get speaking(): boolean {\n    return this.internal.speaking;\n  }\n\n  /**\n   * This attribute is true when the global SpeechSynthesis instance is\n   * in the paused state.\n   * This state is independent of whether anything is in the queue.\n   * The default state of a the global SpeechSynthesis instance\n   * for a new window is the non-paused state.\n   */\n  get paused(): boolean {\n    return this.internal.paused;\n  }\n\n  /**\n   * Fired when the contents of the SpeechSynthesisVoiceList,\n   * that the getVoices method will return, have changed.\n   * Examples include: server-side synthesis where the list is determined asynchronously,\n   * or when client-side voices are installed/uninstalled.\n   */\n  set onvoiceschanged(handler: VoicesChangedEventHandler) {\n    this.internal.onvoiceschanged = handler;\n  }\n\n  /**\n   * This method appends the SpeechSynthesisUtterance object utterance\n   * to the end of the queue for the global SpeechSynthesis instance.\n   * It does not change the paused state of the SpeechSynthesis instance.\n   * If the SpeechSynthesis instance is paused, it remains paused.\n   * If it is not paused and no other utterances are in the queue,\n   * then this utterance is spoken immediately, else this utterance is queued\n   * to begin speaking after the other utterances in the queue have been spoken.\n   * If changes are made to the SpeechSynthesisUtterance object after calling\n   * this method and prior to the corresponding end or error event,\n   * it is not defined whether those changes will affect what is spoken,\n   * and those changes may cause an error to be returned.\n   * The SpeechSynthesis object takes exclusive ownership of the SpeechSynthesisUtterance object.\n   * Passing it as a speak() argument to another SpeechSynthesis object should throw an exception.\n   * (For example, two frames may have the same origin and each will contain a SpeechSynthesis object.)\n   */\n  public speak(utterance: SpeechSynthesisUtterance): void {\n    this.internal.speak(utterance);\n  }\n\n  /**\n   * This method removes all utterances from the queue.\n   * If an utterance is being spoken, speaking ceases immediately.\n   * This method does not change the paused state of the global SpeechSynthesis instance.\n   */\n  public cancel(): void {\n    this.internal.cancel();\n  }\n\n  /**\n   * This method puts the global SpeechSynthesis instance into the paused state.\n   * If an utterance was being spoken, it pauses mid-utterance.\n   * (If called when the SpeechSynthesis instance was already in the paused state, it does nothing.)\n   */\n  public pause(): void {\n    this.internal.pause();\n  }\n\n  /**\n   * This method puts the global SpeechSynthesis instance into the non-paused state.\n   * If an utterance was speaking, it continues speaking the utterance\n   * at the point at which it was paused, else it begins speaking\n   * the next utterance in the queue (if any).\n   * (If called when the SpeechSynthesis instance was already in the non-paused state, it does nothing.)\n   */\n  public resume(): void {\n    this.internal.resume();\n  }\n\n  /**\n   * This method returns the available voices.\n   * It is user agent dependent which voices are available.\n   * If there are no voices available, or if the the list of available voices\n   * is not yet known (for example: server-side synthesis where the list is determined asynchronously),\n   * then this method must return a SpeechSynthesisVoiceList of length zero.\n   */\n  public getVoices(): SpeechSynthesisVoice[] {\n    return this.internal.getVoices();\n  }\n}\n","import { Injectable, Optional, Inject } from '@angular/core';\n\nimport {\n  Lang,\n  Voice,\n  Volume,\n  Rate,\n  Pitch,\n  OnStartHandler,\n  OnEndHandler,\n  OnErrorHandler,\n  OnPauseHandler,\n  OnResumeHandler,\n  OnMarkHandler,\n  OnBoundaryHandler,\n  SpeechSynthesisUtteranceEventHandler,\n  SpeechSynthesisUtteranceConfig,\n  Config,\n  SpeechSynthesisUtteranceErrorEventHandler,\n} from '../configs';\nimport { SpeechSynthesisVoice } from '../adapters/adapter';\n/** @dynamic */\n@Injectable({\n  providedIn: 'root'\n})\nexport class SpeechSynthesisUtteranceFactoryService {\n  private _config?: SpeechSynthesisUtteranceConfig;\n  private _lang?: string;\n  private _voice?: SpeechSynthesisVoice;\n  private _volume?: number;\n  private _rate?: number;\n  private _pitch?: number;\n  private _onstart?: SpeechSynthesisUtteranceEventHandler;\n  private _onend?: SpeechSynthesisUtteranceEventHandler;\n  private _onerror?: SpeechSynthesisUtteranceErrorEventHandler;\n  private _onpause?: SpeechSynthesisUtteranceEventHandler;\n  private _onresume?: SpeechSynthesisUtteranceEventHandler;\n  private _onmark?: SpeechSynthesisUtteranceEventHandler;\n  private _onboundary?: SpeechSynthesisUtteranceEventHandler;\n\n\n  /**\n   * If SpeechSynthesis API is supported\n   * by the browser instance will be included.\n   */\n  private internal: SpeechSynthesis;\n\n  constructor(\n    @Optional() @Inject(Config)\n    config?: SpeechSynthesisUtteranceConfig,\n\n    @Optional() @Inject(Lang)\n    /**\n     * This attribute specifies the language of the speech synthesis for the utterance,\n     * using a valid BCP 47 language tag.\n     * [BCP47] If unset it remains unset for getting in script,\n     * but will default to use the language of the html document root element and associated hierarchy.\n     * This default value is computed and used when the input request opens a connection\n     * to the recognition service.\n     */\n    lang?: string,\n\n    @Optional() @Inject(Voice)\n    /**\n     * This attribute specifies the speech synthesis voice that the web application wishes to use.\n     * When a SpeechSynthesisUtterance object is created this attribute must be initialized to null.\n     * If, at the time of the speak() method call,\n     * this attribute has been set to one of the SpeechSynthesisVoice objects returned by getVoices(),\n     * then the user agent must use that voice. If this attribute is unset or null at the time of the speak()\n     * method call, then the user agent must use a user agent default voice.\n     * The user agent default voice should support the current language (see lang) and\n     * can be a local or remote speech service and can incorporate end user choices via interfaces\n     * provided by the user agent such as browser configuration parameters.\n     */\n    voice?: SpeechSynthesisVoice | string,\n\n    @Optional() @Inject(Volume)\n    /**\n     * This attribute specifies the speaking volume for the utterance.\n     * It ranges between 0 and 1 inclusive, with 0 being the lowest volume and 1 the highest volume,\n     * with a default of 1. If SSML is used, this value will be overridden by prosody tags in the markup.\n     */\n    volume?: number,\n\n    @Optional() @Inject(Rate)\n    /**\n     * This attribute specifies the speaking rate for the utterance.\n     * It is relative to the default rate for this voice.\n     * 1 is the default rate supported by the speech synthesis engine or specific voice\n     * (which should correspond to a normal speaking rate).\n     * 2 is twice as fast, and 0.5 is half as fast. Values below 0.1 or above 10 are strictly disallowed,\n     * but speech synthesis engines or specific voices may constrain the minimum and maximum rates further,\n     * for example, a particular voice may not actually speak faster than 3 times normal\n     * even if you specify a value larger than 3.\n     * If SSML is used, this value will be overridden by prosody tags in the markup.\n     */\n    rate?: number,\n\n    @Optional() @Inject(Pitch)\n    /**\n     * This attribute specifies the speaking pitch for the utterance.\n     * It ranges between 0 and 2 inclusive, with 0 being the lowest pitch and 2 the highest pitch.\n     * 1 corresponds to the default pitch of the speech synthesis engine or specific voice.\n     * Speech synthesis engines or voices may constrain the minimum and maximum rates further.\n     * If SSML is used, this value will be overridden by prosody tags in the markup.\n     */\n    pitch?: number,\n\n    @Optional() @Inject(OnStartHandler)\n    /**\n     * Fired when this utterance has begun to be spoken.\n     */\n    onstart?: SpeechSynthesisUtteranceEventHandler,\n\n    @Optional() @Inject(OnEndHandler)\n    /**\n     * Fired when this utterance has completed being spoken. If this event fires,\n     * the error event must not be fired for this utterance.\n     */\n    onend?: SpeechSynthesisUtteranceEventHandler,\n\n    @Optional() @Inject(OnErrorHandler)\n    /**\n     * Fired if there was an error that prevented successful speaking of this utterance.\n     * If this event fires, the end event must not be fired for this utterance.\n     */\n    onerror?: SpeechSynthesisUtteranceErrorEventHandler,\n\n    @Optional() @Inject(OnPauseHandler)\n    /**\n     * Fired when and if this utterance is paused mid-utterance.\n     */\n    onpause?: SpeechSynthesisUtteranceEventHandler,\n\n    @Optional() @Inject(OnResumeHandler)\n    /**\n     * Fired when and if this utterance is resumed after being paused mid-utterance.\n     * Adding the utterance to the queue while the global SpeechSynthesis instance is in the paused state,\n     * and then calling the resume method does not cause the resume event to be fired,\n     * in this case the utteranceâs start event will be called when the utterance starts.\n     */\n    onresume?: SpeechSynthesisUtteranceEventHandler,\n\n    @Optional() @Inject(OnMarkHandler)\n    /**\n     * Fired when the spoken utterance reaches a named \"mark\" tag in SSML.\n     * [SSML] The user agent must fire this event if the speech synthesis engine provides the event.\n     */\n    onmark?: SpeechSynthesisUtteranceEventHandler,\n\n    @Optional() @Inject(OnBoundaryHandler)\n    /**\n     * Fired when the spoken utterance reaches a word or sentence boundary.\n     * The user agent must fire this event if the speech synthesis engine provides the event.\n     */\n    onboundary?: SpeechSynthesisUtteranceEventHandler,\n\n  ) {\n    this.internal = window.speechSynthesis;\n    this._config = config;\n    this._lang = lang;\n    if (typeof voice === 'string') {\n      this.internal\n        .addEventListener('voiceschanged', () => {\n          this._voice = this.internal\n            .getVoices().find(v => v.name === voice);\n        });\n    } else {\n      this._voice = voice;\n    }\n    this._volume = volume;\n    this._rate = rate;\n    this._pitch = pitch;\n    this._onstart = onstart;\n    this._onend = onend;\n    this._onerror = onerror;\n    this._onpause = onpause;\n    this._onresume = onresume;\n    this._onmark = onmark;\n    this._onboundary = onboundary;\n  }\n\n  /**\n   * This attribute specifies the language of the speech synthesis for the utterance,\n   * using a valid BCP 47 language tag.\n   * [BCP47] If unset it remains unset for getting in script,\n   * but will default to use the language of the html document root element and associated hierarchy.\n   * This default value is computed and used when the input request opens a connection\n   * to the recognition service.\n   */\n  get lang(): string {\n    return this._lang || this._config.lang;\n  }\n\n  set lang(lang: string) {\n    this._lang = lang;\n  }\n\n  /**\n   * This attribute specifies the speech synthesis voice that the web application wishes to use.\n   * When a SpeechSynthesisUtterance object is created this attribute must be initialized to null.\n   * If, at the time of the speak() method call,\n   * this attribute has been set to one of the SpeechSynthesisVoice objects returned by getVoices(),\n   * then the user agent must use that voice. If this attribute is unset or null at the time of the speak()\n   * method call, then the user agent must use a user agent default voice.\n   * The user agent default voice should support the current language (see lang) and\n   * can be a local or remote speech service and can incorporate end user choices via interfaces\n   * provided by the user agent such as browser configuration parameters.\n   */\n  get voice(): SpeechSynthesisVoice {\n    return this._voice || this._config.voice;\n  }\n  set voice(voice: SpeechSynthesisVoice) {\n    this._voice = voice;\n  }\n\n  /**\n   * This attribute specifies the speaking volume for the utterance.\n   * It ranges between 0 and 1 inclusive, with 0 being the lowest volume and 1 the highest volume,\n   * with a default of 1. If SSML is used, this value will be overridden by prosody tags in the markup.\n   */\n  get volume(): number {\n    return this._volume || this._config.volume;\n  }\n\n  set volume(volume: number) {\n    this._volume = volume;\n  }\n\n  /**\n   * This attribute specifies the speaking rate for the utterance.\n   * It is relative to the default rate for this voice.\n   * 1 is the default rate supported by the speech synthesis engine or specific voice\n   * (which should correspond to a normal speaking rate).\n   * 2 is twice as fast, and 0.5 is half as fast. Values below 0.1 or above 10 are strictly disallowed,\n   * but speech synthesis engines or specific voices may constrain the minimum and maximum rates further,\n   * for example, a particular voice may not actually speak faster than 3 times normal\n   * even if you specify a value larger than 3.\n   * If SSML is used, this value will be overridden by prosody tags in the markup.\n   */\n  get rate(): number {\n    return this._rate || this._config.rate;\n  }\n\n  set rate(rate: number) {\n    this._rate = rate;\n  }\n\n  /**\n   * This attribute specifies the speaking pitch for the utterance.\n   * It ranges between 0 and 2 inclusive, with 0 being the lowest pitch and 2 the highest pitch.\n   * 1 corresponds to the default pitch of the speech synthesis engine or specific voice.\n   * Speech synthesis engines or voices may constrain the minimum and maximum rates further.\n   * If SSML is used, this value will be overridden by prosody tags in the markup.\n   */\n  get pitch(): number {\n    return this._pitch || this._config.pitch;\n  }\n\n  set pitch(pitch: number) {\n    this._pitch = pitch;\n  }\n\n  /**\n   * Fired when this utterance has begun to be spoken.\n   */\n  get onstart(): SpeechSynthesisUtteranceEventHandler {\n    return this._onstart || this._config.onstart;\n  }\n\n  set onstart(onstart: SpeechSynthesisUtteranceEventHandler) {\n    this._onstart = onstart;\n  }\n\n  /**\n   * Fired when this utterance has completed being spoken. If this event fires,\n   * the error event must not be fired for this utterance.\n   */\n  get onend(): SpeechSynthesisUtteranceEventHandler {\n    return this._onend || this._config.onend;\n  }\n\n  set onend(onend: SpeechSynthesisUtteranceEventHandler) {\n    this._onend = onend;\n  }\n\n  /**\n   * Fired if there was an error that prevented successful speaking of this utterance.\n   * If this event fires, the end event must not be fired for this utterance.\n   */\n  get onerror(): SpeechSynthesisUtteranceErrorEventHandler {\n    return this._onerror || this._config.onerror;\n  }\n\n  set onerror(onerror: SpeechSynthesisUtteranceErrorEventHandler) {\n    this._onerror = onerror;\n  }\n\n  /**\n   * Fired when and if this utterance is paused mid-utterance.\n   */\n  get onpause(): SpeechSynthesisUtteranceEventHandler {\n    return this._onpause || this._config.onpause;\n  }\n\n  set onpause(onpause: SpeechSynthesisUtteranceEventHandler) {\n    this._onpause = onpause;\n  }\n\n  /**\n   * Fired when and if this utterance is resumed after being paused mid-utterance.\n   * Adding the utterance to the queue while the global SpeechSynthesis instance is in the paused state,\n   * and then calling the resume method does not cause the resume event to be fired,\n   * in this case the utteranceâs start event will be called when the utterance starts.\n   */\n  get onresume(): SpeechSynthesisUtteranceEventHandler {\n    return this._onresume || this._config.onresume;\n  }\n\n  set onresume(onresume: SpeechSynthesisUtteranceEventHandler) {\n    this._onresume = onresume;\n  }\n\n  /**\n   * Fired when the spoken utterance reaches a named \"mark\" tag in SSML.\n   * [SSML] The user agent must fire this event if the speech synthesis engine provides the event.\n   */\n  get onmark(): SpeechSynthesisUtteranceEventHandler {\n    return this._onmark || this._config.onmark;\n  }\n\n  set onmark(onmark: SpeechSynthesisUtteranceEventHandler) {\n    this._onmark = onmark;\n  }\n\n  /**\n   * Fired when the spoken utterance reaches a word or sentence boundary.\n   * The user agent must fire this event if the speech synthesis engine provides the event.\n   */\n  get onboundary(): SpeechSynthesisUtteranceEventHandler {\n    return this._onboundary || this._config.onboundary;\n  }\n\n  set onboundary(onboundary: SpeechSynthesisUtteranceEventHandler) {\n    this._onboundary = onboundary;\n  }\n\n  /**\n   * This attribute specifies the text to be synthesized and spoken for this utterance.\n   * This may be either plain text or a complete, well-formed SSML document.\n   * [SSML] For speech synthesis engines that do not support SSML,\n   * or only support certain tags, the user agent or speech engine must strip away\n   * the tags they do not support and speak the text. There may be a maximum length of the text,\n   * it may be limited to 32,767 characters.\n   */\n  public text(text: string): SpeechSynthesisUtterance {\n    const utterance = new SpeechSynthesisUtterance(text);\n\n    utterance.lang       = this.lang;\n    utterance.voice      = this.voice;\n    utterance.volume     = this.volume;\n    utterance.rate       = this.rate;\n    utterance.pitch      = this.pitch;\n    utterance.onstart    = this.onstart;\n    utterance.onend      = this.onend;\n    utterance.onerror    = this.onerror;\n    utterance.onpause    = this.onpause;\n    utterance.onresume   = this.onresume;\n    utterance.onmark     = this.onmark;\n    utterance.onboundary = this.onboundary;\n\n    return utterance;\n  }\n}\n","import { NgModule, ModuleWithProviders } from '@angular/core';\nimport { SpeechSynthesisUtteranceConfig, Config } from './configs';\n\n@NgModule({\n  declarations: [],\n  imports: [],\n  exports: []\n})\nexport class SpeechSynthesisModule {\n\n  static forRoot(config: SpeechSynthesisUtteranceConfig): ModuleWithProviders {\n    return {\n      ngModule: SpeechSynthesisModule,\n      providers: [\n        {\n          provide: Config,\n          useValue: config,\n        },\n      ],\n    };\n  }\n}\n","/* tslint:disable */\nexport var SpeechSynthesisVoice: SpeechSynthesisVoice = window['SpeechSynthesisVoice'];\n"],"names":[],"mappings":";;;;;;AAAA;AA0BA,MAAa,IAAI,GAAgB,IAAI,cAAc,CAAS,uBAAuB,CAAC;;AACpF,MAAa,KAAK,GAAe,IAAI,cAAc,CAAgC,wBAAwB,CAAC;;AAC5G,MAAa,MAAM,GAAc,IAAI,cAAc,CAAS,yBAAyB,CAAC;;AACtF,MAAa,IAAI,GAAgB,IAAI,cAAc,CAAU,uBAAuB,CAAC;;AACrF,MAAa,KAAK,GAAe,IAAI,cAAc,CAAS,wBAAwB,CAAC;;AACrF,MAAa,cAAc,GAAM,IAAI,cAAc,CAAuC,0BAA0B,CAAC;;AACrH,MAAa,YAAY,GAAQ,IAAI,cAAc,CAAuC,wBAAwB,CAAC;;AACnH,MAAa,cAAc,GAAM,IAAI,cAAc,CAA4C,0BAA0B,CAAC;;AAC1H,MAAa,cAAc,GAAM,IAAI,cAAc,CAAuC,0BAA0B,CAAC;;AACrH,MAAa,eAAe,GAAK,IAAI,cAAc,CAAuC,2BAA2B,CAAC;;AACtH,MAAa,aAAa,GAAO,IAAI,cAAc,CAAuC,yBAAyB,CAAC;;AACpH,MAAa,iBAAiB,GAAG,IAAI,cAAc,CAAuC,6BAA6B,CAAC;;AACxH,MAAa,MAAM,GAAc,IAAI,cAAc,CAAiC,yBAAyB,CAAC;;AAC9G,MAAa,MAAM,GAAc,IAAI,cAAc,CAAiC,yBAAyB,CAAC;;;;;;ACvC9G,MAOa,sBAAsB;IAQjC;QACE,IAAI,CAAC,QAAQ,GAAG,MAAM,CAAC,eAAe,CAAC;KACxC;;;;;;;IAQD,IAAI,OAAO;QACT,OAAO,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC;KAC9B;;;;;;;;;IASD,IAAI,QAAQ;QACV,OAAO,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAAC;KAC/B;;;;;;;;;IASD,IAAI,MAAM;QACR,OAAO,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC;KAC7B;;;;;;;;;IAQD,IAAI,eAAe,CAAC,OAAkC;QACpD,IAAI,CAAC,QAAQ,CAAC,eAAe,GAAG,OAAO,CAAC;KACzC;;;;;;;;;;;;;;;;;;;IAkBM,KAAK,CAAC,SAAmC;QAC9C,IAAI,CAAC,QAAQ,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC;KAChC;;;;;;;IAOM,MAAM;QACX,IAAI,CAAC,QAAQ,CAAC,MAAM,EAAE,CAAC;KACxB;;;;;;;IAOM,KAAK;QACV,IAAI,CAAC,QAAQ,CAAC,KAAK,EAAE,CAAC;KACvB;;;;;;;;;IASM,MAAM;QACX,IAAI,CAAC,QAAQ,CAAC,MAAM,EAAE,CAAC;KACxB;;;;;;;;;IASM,SAAS;QACd,OAAO,IAAI,CAAC,QAAQ,CAAC,SAAS,EAAE,CAAC;KAClC;;;YAnHF,UAAU,SAAC;gBACV,UAAU,EAAE,MAAM;aACnB;;;;;;;;;;ACND;;;AAyBA,MAAa,sCAAsC;;;;;;;;;;;;;;;;IAsBjD,YAEE,MAAuC;;;;;;;;;IAWvC,IAAa;;;;;;;;;;;;IAcb,KAAqC;;;;;;IAQrC,MAAe;;;;;;;;;;;;IAcf,IAAa;;;;;;;;IAUb,KAAc;;;;IAMd,OAA8C;;;;;IAO9C,KAA4C;;;;;IAO5C,OAAmD;;;;IAMnD,OAA8C;;;;;;;IAS9C,QAA+C;;;;;IAO/C,MAA6C;;;;;IAO7C,UAAiD;QAGjD,IAAI,CAAC,QAAQ,GAAG,MAAM,CAAC,eAAe,CAAC;QACvC,IAAI,CAAC,OAAO,GAAG,MAAM,CAAC;QACtB,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;QAClB,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE;YAC7B,IAAI,CAAC,QAAQ;iBACV,gBAAgB,CAAC,eAAe,EAAE;gBACjC,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,QAAQ;qBACxB,SAAS,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,CAAC,IAAI,KAAK,KAAK,CAAC,CAAC;aAC5C,CAAC,CAAC;SACN;aAAM;YACL,IAAI,CAAC,MAAM,GAAG,KAAK,CAAC;SACrB;QACD,IAAI,CAAC,OAAO,GAAG,MAAM,CAAC;QACtB,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;QAClB,IAAI,CAAC,MAAM,GAAG,KAAK,CAAC;QACpB,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC;QACxB,IAAI,CAAC,MAAM,GAAG,KAAK,CAAC;QACpB,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC;QACxB,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC;QACxB,IAAI,CAAC,SAAS,GAAG,QAAQ,CAAC;QAC1B,IAAI,CAAC,OAAO,GAAG,MAAM,CAAC;QACtB,IAAI,CAAC,WAAW,GAAG,UAAU,CAAC;KAC/B;;;;;;;;;;IAUD,IAAI,IAAI;QACN,OAAO,IAAI,CAAC,KAAK,IAAI,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC;KACxC;;;;;IAED,IAAI,IAAI,CAAC,IAAY;QACnB,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;KACnB;;;;;;;;;;;;;IAaD,IAAI,KAAK;QACP,OAAO,IAAI,CAAC,MAAM,IAAI,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC;KAC1C;;;;;IACD,IAAI,KAAK,CAAC,KAA2B;QACnC,IAAI,CAAC,MAAM,GAAG,KAAK,CAAC;KACrB;;;;;;;IAOD,IAAI,MAAM;QACR,OAAO,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC;KAC5C;;;;;IAED,IAAI,MAAM,CAAC,MAAc;QACvB,IAAI,CAAC,OAAO,GAAG,MAAM,CAAC;KACvB;;;;;;;;;;;;;IAaD,IAAI,IAAI;QACN,OAAO,IAAI,CAAC,KAAK,IAAI,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC;KACxC;;;;;IAED,IAAI,IAAI,CAAC,IAAY;QACnB,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;KACnB;;;;;;;;;IASD,IAAI,KAAK;QACP,OAAO,IAAI,CAAC,MAAM,IAAI,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC;KAC1C;;;;;IAED,IAAI,KAAK,CAAC,KAAa;QACrB,IAAI,CAAC,MAAM,GAAG,KAAK,CAAC;KACrB;;;;;IAKD,IAAI,OAAO;QACT,OAAO,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC;KAC9C;;;;;IAED,IAAI,OAAO,CAAC,OAA6C;QACvD,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC;KACzB;;;;;;IAMD,IAAI,KAAK;QACP,OAAO,IAAI,CAAC,MAAM,IAAI,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC;KAC1C;;;;;IAED,IAAI,KAAK,CAAC,KAA2C;QACnD,IAAI,CAAC,MAAM,GAAG,KAAK,CAAC;KACrB;;;;;;IAMD,IAAI,OAAO;QACT,OAAO,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC;KAC9C;;;;;IAED,IAAI,OAAO,CAAC,OAAkD;QAC5D,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC;KACzB;;;;;IAKD,IAAI,OAAO;QACT,OAAO,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC;KAC9C;;;;;IAED,IAAI,OAAO,CAAC,OAA6C;QACvD,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC;KACzB;;;;;;;;IAQD,IAAI,QAAQ;QACV,OAAO,IAAI,CAAC,SAAS,IAAI,IAAI,CAAC,OAAO,CAAC,QAAQ,CAAC;KAChD;;;;;IAED,IAAI,QAAQ,CAAC,QAA8C;QACzD,IAAI,CAAC,SAAS,GAAG,QAAQ,CAAC;KAC3B;;;;;;IAMD,IAAI,MAAM;QACR,OAAO,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC;KAC5C;;;;;IAED,IAAI,MAAM,CAAC,MAA4C;QACrD,IAAI,CAAC,OAAO,GAAG,MAAM,CAAC;KACvB;;;;;;IAMD,IAAI,UAAU;QACZ,OAAO,IAAI,CAAC,WAAW,IAAI,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC;KACpD;;;;;IAED,IAAI,UAAU,CAAC,UAAgD;QAC7D,IAAI,CAAC,WAAW,GAAG,UAAU,CAAC;KAC/B;;;;;;;;;;;IAUM,IAAI,CAAC,IAAY;;cAChB,SAAS,GAAG,IAAI,wBAAwB,CAAC,IAAI,CAAC;QAEpD,SAAS,CAAC,IAAI,GAAS,IAAI,CAAC,IAAI,CAAC;QACjC,SAAS,CAAC,KAAK,GAAQ,IAAI,CAAC,KAAK,CAAC;QAClC,SAAS,CAAC,MAAM,GAAO,IAAI,CAAC,MAAM,CAAC;QACnC,SAAS,CAAC,IAAI,GAAS,IAAI,CAAC,IAAI,CAAC;QACjC,SAAS,CAAC,KAAK,GAAQ,IAAI,CAAC,KAAK,CAAC;QAClC,SAAS,CAAC,OAAO,GAAM,IAAI,CAAC,OAAO,CAAC;QACpC,SAAS,CAAC,KAAK,GAAQ,IAAI,CAAC,KAAK,CAAC;QAClC,SAAS,CAAC,OAAO,GAAM,IAAI,CAAC,OAAO,CAAC;QACpC,SAAS,CAAC,OAAO,GAAM,IAAI,CAAC,OAAO,CAAC;QACpC,SAAS,CAAC,QAAQ,GAAK,IAAI,CAAC,QAAQ,CAAC;QACrC,SAAS,CAAC,MAAM,GAAO,IAAI,CAAC,MAAM,CAAC;QACnC,SAAS,CAAC,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC;QAEvC,OAAO,SAAS,CAAC;KAClB;;;YA9VF,UAAU,SAAC;gBACV,UAAU,EAAE,MAAM;aACnB;;;;4CAwBI,QAAQ,YAAI,MAAM,SAAC,MAAM;yCAGzB,QAAQ,YAAI,MAAM,SAAC,IAAI;4CAWvB,QAAQ,YAAI,MAAM,SAAC,KAAK;yCAcxB,QAAQ,YAAI,MAAM,SAAC,MAAM;yCAQzB,QAAQ,YAAI,MAAM,SAAC,IAAI;yCAcvB,QAAQ,YAAI,MAAM,SAAC,KAAK;4CAUxB,QAAQ,YAAI,MAAM,SAAC,cAAc;4CAMjC,QAAQ,YAAI,MAAM,SAAC,YAAY;4CAO/B,QAAQ,YAAI,MAAM,SAAC,cAAc;4CAOjC,QAAQ,YAAI,MAAM,SAAC,cAAc;4CAMjC,QAAQ,YAAI,MAAM,SAAC,eAAe;4CASlC,QAAQ,YAAI,MAAM,SAAC,aAAa;4CAOhC,QAAQ,YAAI,MAAM,SAAC,iBAAiB;;;;;;;;ACtJzC,MAQa,qBAAqB;;;;;IAEhC,OAAO,OAAO,CAAC,MAAsC;QACnD,OAAO;YACL,QAAQ,EAAE,qBAAqB;YAC/B,SAAS,EAAE;gBACT;oBACE,OAAO,EAAE,MAAM;oBACf,QAAQ,EAAE,MAAM;iBACjB;aACF;SACF,CAAC;KACH;;;YAjBF,QAAQ,SAAC;gBACR,YAAY,EAAE,EAAE;gBAChB,OAAO,EAAE,EAAE;gBACX,OAAO,EAAE,EAAE;aACZ;;;;;;;;;;;;;;ACND,IAAW,oBAAoB,GAAyB,MAAM,CAAC,sBAAsB,CAAC;;;;;;;;;"}
