import { InjectionToken, Injectable, NgModule, Optional, Inject, defineInjectable, inject } from '@angular/core';

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
/** @type {?} */
const Lang = new InjectionToken('speech-synthesis.lang');
/** @type {?} */
const Voice = new InjectionToken('speech-synthesis.voice');
/** @type {?} */
const Volume = new InjectionToken('speech-synthesis.volume');
/** @type {?} */
const Rate = new InjectionToken('speech-synthesis.rate');
/** @type {?} */
const Pitch = new InjectionToken('speech-synthesis.pitch');
/** @type {?} */
const OnStartHandler = new InjectionToken('speech-synthesis.onstart');
/** @type {?} */
const OnEndHandler = new InjectionToken('speech-synthesis.onend');
/** @type {?} */
const OnErrorHandler = new InjectionToken('speech-synthesis.onerror');
/** @type {?} */
const OnPauseHandler = new InjectionToken('speech-synthesis.onpause');
/** @type {?} */
const OnResumeHandler = new InjectionToken('speech-synthesis.onresume');
/** @type {?} */
const OnMarkHandler = new InjectionToken('speech-synthesis.onmark');
/** @type {?} */
const OnBoundaryHandler = new InjectionToken('speech-synthesis.onboundary');
/** @type {?} */
const Params = new InjectionToken('speech-synthesis.params');
/** @type {?} */
const Config = new InjectionToken('speech-synthesis.config');

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
class SpeechSynthesisService {
    constructor() {
        this.internal = window.speechSynthesis;
    }
    /**
     * This attribute is true if the queue for
     * the global SpeechSynthesis instance contains any utterances
     * which have not started speaking.
     * @return {?}
     */
    get pending() {
        return this.internal.pending;
    }
    /**
     * This attribute is true if an utterance is being spoken.
     * Specifically if an utterance has begun being spoken
     * and has not completed being spoken.
     * This is independent of whether the global SpeechSynthesis instance is
     * in the paused state.
     * @return {?}
     */
    get speaking() {
        return this.internal.speaking;
    }
    /**
     * This attribute is true when the global SpeechSynthesis instance is
     * in the paused state.
     * This state is independent of whether anything is in the queue.
     * The default state of a the global SpeechSynthesis instance
     * for a new window is the non-paused state.
     * @return {?}
     */
    get paused() {
        return this.internal.paused;
    }
    /**
     * Fired when the contents of the SpeechSynthesisVoiceList,
     * that the getVoices method will return, have changed.
     * Examples include: server-side synthesis where the list is determined asynchronously,
     * or when client-side voices are installed/uninstalled.
     * @param {?} handler
     * @return {?}
     */
    set onvoiceschanged(handler) {
        this.internal.onvoiceschanged = handler;
    }
    /**
     * This method appends the SpeechSynthesisUtterance object utterance
     * to the end of the queue for the global SpeechSynthesis instance.
     * It does not change the paused state of the SpeechSynthesis instance.
     * If the SpeechSynthesis instance is paused, it remains paused.
     * If it is not paused and no other utterances are in the queue,
     * then this utterance is spoken immediately, else this utterance is queued
     * to begin speaking after the other utterances in the queue have been spoken.
     * If changes are made to the SpeechSynthesisUtterance object after calling
     * this method and prior to the corresponding end or error event,
     * it is not defined whether those changes will affect what is spoken,
     * and those changes may cause an error to be returned.
     * The SpeechSynthesis object takes exclusive ownership of the SpeechSynthesisUtterance object.
     * Passing it as a speak() argument to another SpeechSynthesis object should throw an exception.
     * (For example, two frames may have the same origin and each will contain a SpeechSynthesis object.)
     * @param {?} utterance
     * @return {?}
     */
    speak(utterance) {
        this.internal.speak(utterance);
    }
    /**
     * This method removes all utterances from the queue.
     * If an utterance is being spoken, speaking ceases immediately.
     * This method does not change the paused state of the global SpeechSynthesis instance.
     * @return {?}
     */
    cancel() {
        this.internal.cancel();
    }
    /**
     * This method puts the global SpeechSynthesis instance into the paused state.
     * If an utterance was being spoken, it pauses mid-utterance.
     * (If called when the SpeechSynthesis instance was already in the paused state, it does nothing.)
     * @return {?}
     */
    pause() {
        this.internal.pause();
    }
    /**
     * This method puts the global SpeechSynthesis instance into the non-paused state.
     * If an utterance was speaking, it continues speaking the utterance
     * at the point at which it was paused, else it begins speaking
     * the next utterance in the queue (if any).
     * (If called when the SpeechSynthesis instance was already in the non-paused state, it does nothing.)
     * @return {?}
     */
    resume() {
        this.internal.resume();
    }
    /**
     * This method returns the available voices.
     * It is user agent dependent which voices are available.
     * If there are no voices available, or if the the list of available voices
     * is not yet known (for example: server-side synthesis where the list is determined asynchronously),
     * then this method must return a SpeechSynthesisVoiceList of length zero.
     * @return {?}
     */
    getVoices() {
        return this.internal.getVoices();
    }
}
SpeechSynthesisService.decorators = [
    { type: Injectable, args: [{
                providedIn: 'root'
            },] }
];
/** @nocollapse */
SpeechSynthesisService.ctorParameters = () => [];
/** @nocollapse */ SpeechSynthesisService.ngInjectableDef = defineInjectable({ factory: function SpeechSynthesisService_Factory() { return new SpeechSynthesisService(); }, token: SpeechSynthesisService, providedIn: "root" });

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
/**
 * \@dynamic
 */
class SpeechSynthesisUtteranceFactoryService {
    /**
     * @param {?=} config
     * @param {?=} lang
     * @param {?=} voice
     * @param {?=} volume
     * @param {?=} rate
     * @param {?=} pitch
     * @param {?=} onstart
     * @param {?=} onend
     * @param {?=} onerror
     * @param {?=} onpause
     * @param {?=} onresume
     * @param {?=} onmark
     * @param {?=} onboundary
     */
    constructor(config, 
    /**
     * This attribute specifies the language of the speech synthesis for the utterance,
     * using a valid BCP 47 language tag.
     * [BCP47] If unset it remains unset for getting in script,
     * but will default to use the language of the html document root element and associated hierarchy.
     * This default value is computed and used when the input request opens a connection
     * to the recognition service.
     */
    lang, 
    /**
     * This attribute specifies the speech synthesis voice that the web application wishes to use.
     * When a SpeechSynthesisUtterance object is created this attribute must be initialized to null.
     * If, at the time of the speak() method call,
     * this attribute has been set to one of the SpeechSynthesisVoice objects returned by getVoices(),
     * then the user agent must use that voice. If this attribute is unset or null at the time of the speak()
     * method call, then the user agent must use a user agent default voice.
     * The user agent default voice should support the current language (see lang) and
     * can be a local or remote speech service and can incorporate end user choices via interfaces
     * provided by the user agent such as browser configuration parameters.
     */
    voice, 
    /**
     * This attribute specifies the speaking volume for the utterance.
     * It ranges between 0 and 1 inclusive, with 0 being the lowest volume and 1 the highest volume,
     * with a default of 1. If SSML is used, this value will be overridden by prosody tags in the markup.
     */
    volume, 
    /**
     * This attribute specifies the speaking rate for the utterance.
     * It is relative to the default rate for this voice.
     * 1 is the default rate supported by the speech synthesis engine or specific voice
     * (which should correspond to a normal speaking rate).
     * 2 is twice as fast, and 0.5 is half as fast. Values below 0.1 or above 10 are strictly disallowed,
     * but speech synthesis engines or specific voices may constrain the minimum and maximum rates further,
     * for example, a particular voice may not actually speak faster than 3 times normal
     * even if you specify a value larger than 3.
     * If SSML is used, this value will be overridden by prosody tags in the markup.
     */
    rate, 
    /**
     * This attribute specifies the speaking pitch for the utterance.
     * It ranges between 0 and 2 inclusive, with 0 being the lowest pitch and 2 the highest pitch.
     * 1 corresponds to the default pitch of the speech synthesis engine or specific voice.
     * Speech synthesis engines or voices may constrain the minimum and maximum rates further.
     * If SSML is used, this value will be overridden by prosody tags in the markup.
     */
    pitch, 
    /**
     * Fired when this utterance has begun to be spoken.
     */
    onstart, 
    /**
     * Fired when this utterance has completed being spoken. If this event fires,
     * the error event must not be fired for this utterance.
     */
    onend, 
    /**
     * Fired if there was an error that prevented successful speaking of this utterance.
     * If this event fires, the end event must not be fired for this utterance.
     */
    onerror, 
    /**
     * Fired when and if this utterance is paused mid-utterance.
     */
    onpause, 
    /**
     * Fired when and if this utterance is resumed after being paused mid-utterance.
     * Adding the utterance to the queue while the global SpeechSynthesis instance is in the paused state,
     * and then calling the resume method does not cause the resume event to be fired,
     * in this case the utterance’s start event will be called when the utterance starts.
     */
    onresume, 
    /**
     * Fired when the spoken utterance reaches a named "mark" tag in SSML.
     * [SSML] The user agent must fire this event if the speech synthesis engine provides the event.
     */
    onmark, 
    /**
     * Fired when the spoken utterance reaches a word or sentence boundary.
     * The user agent must fire this event if the speech synthesis engine provides the event.
     */
    onboundary) {
        this.internal = window.speechSynthesis;
        this._config = config;
        this._lang = lang;
        if (typeof voice === 'string') {
            this.internal
                .addEventListener('voiceschanged', () => {
                this._voice = this.internal
                    .getVoices().find(v => v.name === voice);
            });
        }
        else {
            this._voice = voice;
        }
        this._volume = volume;
        this._rate = rate;
        this._pitch = pitch;
        this._onstart = onstart;
        this._onend = onend;
        this._onerror = onerror;
        this._onpause = onpause;
        this._onresume = onresume;
        this._onmark = onmark;
        this._onboundary = onboundary;
    }
    /**
     * This attribute specifies the language of the speech synthesis for the utterance,
     * using a valid BCP 47 language tag.
     * [BCP47] If unset it remains unset for getting in script,
     * but will default to use the language of the html document root element and associated hierarchy.
     * This default value is computed and used when the input request opens a connection
     * to the recognition service.
     * @return {?}
     */
    get lang() {
        return this._lang || this._config.lang;
    }
    /**
     * @param {?} lang
     * @return {?}
     */
    set lang(lang) {
        this._lang = lang;
    }
    /**
     * This attribute specifies the speech synthesis voice that the web application wishes to use.
     * When a SpeechSynthesisUtterance object is created this attribute must be initialized to null.
     * If, at the time of the speak() method call,
     * this attribute has been set to one of the SpeechSynthesisVoice objects returned by getVoices(),
     * then the user agent must use that voice. If this attribute is unset or null at the time of the speak()
     * method call, then the user agent must use a user agent default voice.
     * The user agent default voice should support the current language (see lang) and
     * can be a local or remote speech service and can incorporate end user choices via interfaces
     * provided by the user agent such as browser configuration parameters.
     * @return {?}
     */
    get voice() {
        return this._voice || this._config.voice;
    }
    /**
     * @param {?} voice
     * @return {?}
     */
    set voice(voice) {
        this._voice = voice;
    }
    /**
     * This attribute specifies the speaking volume for the utterance.
     * It ranges between 0 and 1 inclusive, with 0 being the lowest volume and 1 the highest volume,
     * with a default of 1. If SSML is used, this value will be overridden by prosody tags in the markup.
     * @return {?}
     */
    get volume() {
        return this._volume || this._config.volume;
    }
    /**
     * @param {?} volume
     * @return {?}
     */
    set volume(volume) {
        this._volume = volume;
    }
    /**
     * This attribute specifies the speaking rate for the utterance.
     * It is relative to the default rate for this voice.
     * 1 is the default rate supported by the speech synthesis engine or specific voice
     * (which should correspond to a normal speaking rate).
     * 2 is twice as fast, and 0.5 is half as fast. Values below 0.1 or above 10 are strictly disallowed,
     * but speech synthesis engines or specific voices may constrain the minimum and maximum rates further,
     * for example, a particular voice may not actually speak faster than 3 times normal
     * even if you specify a value larger than 3.
     * If SSML is used, this value will be overridden by prosody tags in the markup.
     * @return {?}
     */
    get rate() {
        return this._rate || this._config.rate;
    }
    /**
     * @param {?} rate
     * @return {?}
     */
    set rate(rate) {
        this._rate = rate;
    }
    /**
     * This attribute specifies the speaking pitch for the utterance.
     * It ranges between 0 and 2 inclusive, with 0 being the lowest pitch and 2 the highest pitch.
     * 1 corresponds to the default pitch of the speech synthesis engine or specific voice.
     * Speech synthesis engines or voices may constrain the minimum and maximum rates further.
     * If SSML is used, this value will be overridden by prosody tags in the markup.
     * @return {?}
     */
    get pitch() {
        return this._pitch || this._config.pitch;
    }
    /**
     * @param {?} pitch
     * @return {?}
     */
    set pitch(pitch) {
        this._pitch = pitch;
    }
    /**
     * Fired when this utterance has begun to be spoken.
     * @return {?}
     */
    get onstart() {
        return this._onstart || this._config.onstart;
    }
    /**
     * @param {?} onstart
     * @return {?}
     */
    set onstart(onstart) {
        this._onstart = onstart;
    }
    /**
     * Fired when this utterance has completed being spoken. If this event fires,
     * the error event must not be fired for this utterance.
     * @return {?}
     */
    get onend() {
        return this._onend || this._config.onend;
    }
    /**
     * @param {?} onend
     * @return {?}
     */
    set onend(onend) {
        this._onend = onend;
    }
    /**
     * Fired if there was an error that prevented successful speaking of this utterance.
     * If this event fires, the end event must not be fired for this utterance.
     * @return {?}
     */
    get onerror() {
        return this._onerror || this._config.onerror;
    }
    /**
     * @param {?} onerror
     * @return {?}
     */
    set onerror(onerror) {
        this._onerror = onerror;
    }
    /**
     * Fired when and if this utterance is paused mid-utterance.
     * @return {?}
     */
    get onpause() {
        return this._onpause || this._config.onpause;
    }
    /**
     * @param {?} onpause
     * @return {?}
     */
    set onpause(onpause) {
        this._onpause = onpause;
    }
    /**
     * Fired when and if this utterance is resumed after being paused mid-utterance.
     * Adding the utterance to the queue while the global SpeechSynthesis instance is in the paused state,
     * and then calling the resume method does not cause the resume event to be fired,
     * in this case the utterance’s start event will be called when the utterance starts.
     * @return {?}
     */
    get onresume() {
        return this._onresume || this._config.onresume;
    }
    /**
     * @param {?} onresume
     * @return {?}
     */
    set onresume(onresume) {
        this._onresume = onresume;
    }
    /**
     * Fired when the spoken utterance reaches a named "mark" tag in SSML.
     * [SSML] The user agent must fire this event if the speech synthesis engine provides the event.
     * @return {?}
     */
    get onmark() {
        return this._onmark || this._config.onmark;
    }
    /**
     * @param {?} onmark
     * @return {?}
     */
    set onmark(onmark) {
        this._onmark = onmark;
    }
    /**
     * Fired when the spoken utterance reaches a word or sentence boundary.
     * The user agent must fire this event if the speech synthesis engine provides the event.
     * @return {?}
     */
    get onboundary() {
        return this._onboundary || this._config.onboundary;
    }
    /**
     * @param {?} onboundary
     * @return {?}
     */
    set onboundary(onboundary) {
        this._onboundary = onboundary;
    }
    /**
     * This attribute specifies the text to be synthesized and spoken for this utterance.
     * This may be either plain text or a complete, well-formed SSML document.
     * [SSML] For speech synthesis engines that do not support SSML,
     * or only support certain tags, the user agent or speech engine must strip away
     * the tags they do not support and speak the text. There may be a maximum length of the text,
     * it may be limited to 32,767 characters.
     * @param {?} text
     * @return {?}
     */
    text(text) {
        /** @type {?} */
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = this.lang;
        utterance.voice = this.voice;
        utterance.volume = this.volume;
        utterance.rate = this.rate;
        utterance.pitch = this.pitch;
        utterance.onstart = this.onstart;
        utterance.onend = this.onend;
        utterance.onerror = this.onerror;
        utterance.onpause = this.onpause;
        utterance.onresume = this.onresume;
        utterance.onmark = this.onmark;
        utterance.onboundary = this.onboundary;
        return utterance;
    }
}
SpeechSynthesisUtteranceFactoryService.decorators = [
    { type: Injectable, args: [{
                providedIn: 'root'
            },] }
];
/** @nocollapse */
SpeechSynthesisUtteranceFactoryService.ctorParameters = () => [
    { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [Config,] }] },
    { type: String, decorators: [{ type: Optional }, { type: Inject, args: [Lang,] }] },
    { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [Voice,] }] },
    { type: Number, decorators: [{ type: Optional }, { type: Inject, args: [Volume,] }] },
    { type: Number, decorators: [{ type: Optional }, { type: Inject, args: [Rate,] }] },
    { type: Number, decorators: [{ type: Optional }, { type: Inject, args: [Pitch,] }] },
    { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [OnStartHandler,] }] },
    { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [OnEndHandler,] }] },
    { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [OnErrorHandler,] }] },
    { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [OnPauseHandler,] }] },
    { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [OnResumeHandler,] }] },
    { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [OnMarkHandler,] }] },
    { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [OnBoundaryHandler,] }] }
];
/** @nocollapse */ SpeechSynthesisUtteranceFactoryService.ngInjectableDef = defineInjectable({ factory: function SpeechSynthesisUtteranceFactoryService_Factory() { return new SpeechSynthesisUtteranceFactoryService(inject(Config, 8), inject(Lang, 8), inject(Voice, 8), inject(Volume, 8), inject(Rate, 8), inject(Pitch, 8), inject(OnStartHandler, 8), inject(OnEndHandler, 8), inject(OnErrorHandler, 8), inject(OnPauseHandler, 8), inject(OnResumeHandler, 8), inject(OnMarkHandler, 8), inject(OnBoundaryHandler, 8)); }, token: SpeechSynthesisUtteranceFactoryService, providedIn: "root" });

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
class SpeechSynthesisModule {
    /**
     * @param {?} config
     * @return {?}
     */
    static forRoot(config) {
        return {
            ngModule: SpeechSynthesisModule,
            providers: [
                {
                    provide: Config,
                    useValue: config,
                },
            ],
        };
    }
}
SpeechSynthesisModule.decorators = [
    { type: NgModule, args: [{
                declarations: [],
                imports: [],
                exports: []
            },] }
];

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
/* tslint:disable */
/** @type {?} */
var SpeechSynthesisVoice = window['SpeechSynthesisVoice'];

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */

export { Lang, Voice, Volume, Rate, Pitch, OnStartHandler, OnEndHandler, OnErrorHandler, OnPauseHandler, OnResumeHandler, OnMarkHandler, OnBoundaryHandler, Params, Config, SpeechSynthesisService, SpeechSynthesisUtteranceFactoryService, SpeechSynthesisModule, SpeechSynthesisVoice as ɵa };

//# sourceMappingURL=kamiazya-ngx-speech-synthesis.js.map